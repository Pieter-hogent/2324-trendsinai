{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:35:18.107567Z",
     "start_time": "2023-11-20T15:35:17.665207Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "edenai_api_key = os.getenv('EDENAI_API_KEY')\n",
    "\n",
    "# print (openai.api_key)\n",
    "# print (edenai_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Als je de print commando's uitvoert, zou je de key(s) die je wilt gebruiken moeten zien, als je `None` ziet staan is er iets mis.\n",
    "\n",
    "De key van EdenAI is een Bearer token, daar kennen jullie alles van uit de Webservices cursus. Rechtstreeks de EdenAI API aanspreken doe je met een POST request naar de juiste url.\n",
    "EdenAI heeft véél endpoints, een ChatGPT request zou er als volgt uitzien:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88c88e58a348b026"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c13e3d737038ed61"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from langchain.llms import EdenAI, OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.embeddings.edenai import EdenAiEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "class API(Enum):\n",
    "    OPEN_AI = 1\n",
    "    GPT4All = 2\n",
    "    EDEN_AI = 3\n",
    "    \n",
    "\n",
    "def get_llm(which_model=API.OPEN_AI, temperature = 0.0):\n",
    "    if which_model == API.OPEN_AI:\n",
    "        # OpenAI heeft ook een ChatModel, maar dat is niet makkelijk transparent te gebruiken als je ook EdenAI wil gebruiken in dezelfde requests. Als je enkel met OpenAI wenst te werken is dit zeker een goede optie. Je zal dan wel het output formaat moeten aanpassen.\n",
    "        # return ChatOpenAI(temperature=temperature, model=\"gpt-3.5-turbo\")\n",
    "        return OpenAI(temperature=temperature)\n",
    "    elif which_model == API.EDEN_AI:\n",
    "        return EdenAI(edenai_api_key=edenai_api_key,provider=\"openai\", model=\"gpt-3.5-turbo-instruct\", temperature=temperature, max_tokens=250)\n",
    "\n",
    "def get_embedding(which_model=API.OPEN_AI):\n",
    "    if which_model == API.OPEN_AI:\n",
    "        return OpenAIEmbeddings()\n",
    "    elif which_model == API.EDEN_AI:\n",
    "        return EdenAiEmbeddings(edenai_api_key=edenai_api_key,provider=\"openai\")\n",
    "       "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T13:38:03.765429Z",
     "start_time": "2023-12-07T13:38:03.747267Z"
    }
   },
   "id": "7f9bdc0f515ebf93"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "preferred_model = API.OPEN_AI\n",
    "\n",
    "# llm = get_llm(API.EDEN_AI, 0.0)\n",
    "# creative_llm = get_llm(API.EDEN_AI, 0.9)\n",
    "llm = get_llm(preferred_model, 0.0)\n",
    "creative_llm = get_llm(preferred_model, 0.9)\n",
    "embeddings = get_embedding(preferred_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T13:38:05.733301Z",
     "start_time": "2023-12-07T13:38:05.709189Z"
    }
   },
   "id": "3afea169b09d5047"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat with your data\n",
    "\n",
    "![langchain](img/langchain.jpg)\n",
    "\n",
    "(image credit: langchain.com)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13dd0747ea16853"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Document Loading\n",
    "\n",
    "Extra data kan in allerlei formaten voorkomen, PDF, JSON, tekst, ... en kan zowel gestructureerd of ongestructureerd zijn.\n",
    "\n",
    "Om dit te illustreren starten we met een PDF van \"The Little Book on Deep Learning\" (https://fleuret.org/public/lbdl.pdf), vooral omdat deze een creative commons license heeft."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd4052ba1bc7bec"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "168"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/lbdl.pdf\")\n",
    "pages = loader.load()\n",
    "len(pages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:14:13.297347Z",
     "start_time": "2023-11-15T10:14:11.452358Z"
    }
   },
   "id": "547e97a9e03d1c56"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Under and overfitting\n",
      "A key element is the interplay between the capac-\n",
      "ity of the model, that is its flexibility and ability\n",
      "to fit diverse data, and the amount and quality\n",
      "of the training data. When the capacity is insuf-\n",
      "ficient, the model cannot fit the data, resulting\n",
      "in a high error during training. This is referred\n",
      "to as underfitting.\n",
      "On the contrary, when the amount of data is in-\n",
      "sufficient, as illustrated in Figure 1.2, the model\n",
      "will often learn characteristics specific to the\n",
      "tra\n",
      "{'source': 'data/lbdl.pdf', 'page': 15}\n"
     ]
    }
   ],
   "source": [
    "print(pages[15].page_content[:500])\n",
    "print(pages[15].metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:14:15.329708Z",
     "start_time": "2023-11-15T10:14:15.326953Z"
    }
   },
   "id": "7233034c74c88100"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Youtube\n",
    "\n",
    "Maar je kan ook youtube video's als input nemen, we combineren de audio loader van youtube, and de OpenAI whisper parser, die samen een youtube video omzetten in een stuk tekst dat als bron kan dienen.\n",
    "(om dit te doen werken heb je ook ffmpeg nodig, MacOS/Linux: `brew/apt-get/... install ffmpeg`, Windows: downloaden en prutsen)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdcea0c78ceb57da"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# yt_dlp heeft ffmpeg nodig; dus we zorgen dat het in het standaard path gevonden wordt\n",
    "# onderstaande paden zijn typisch voor MacOS homebrew, je zal ze waarschijnlijk moeten aanpassen naargelang je OS en waar je ffmpeg geïnstalleerd hebt\n",
    "import sys\n",
    "sys.path.append('/opt/homebrew/bin/ffmpeg')\n",
    "sys.path.append('/opt/homebrew/bin/ffprobe')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T14:46:20.584487Z",
     "start_time": "2023-10-25T14:46:20.580575Z"
    }
   },
   "id": "9acc799fcb9f167b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser # enkel OpenAI\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T14:46:22.715788Z",
     "start_time": "2023-10-25T14:46:22.664906Z"
    }
   },
   "id": "b5d313a207f81ba4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Token var=<ContextVar name='ffmpeg_location' default=None at 0x177e5f510> at 0x28d1e3640>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from yt_dlp.postprocessor import FFmpegPostProcessor\n",
    "# FFmpegPostProcessor._ffmpeg_location.set('/opt/homebrew/bin/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T14:41:51.702463Z",
     "start_time": "2023-10-25T14:41:51.698361Z"
    }
   },
   "id": "27ded5106e6dc3f3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=TQQlZhbC5ps\n",
      "[youtube] TQQlZhbC5ps: Downloading webpage\n",
      "[youtube] TQQlZhbC5ps: Downloading ios player API JSON\n",
      "[youtube] TQQlZhbC5ps: Downloading android player API JSON\n",
      "[youtube] TQQlZhbC5ps: Downloading m3u8 information\n",
      "[info] TQQlZhbC5ps: Downloading 1 format(s): 140\n",
      "[download] Destination: data/youtube//Transformer Neural Networks - EXPLAINED! (Attention is all you need).m4a\n",
      "[download] 100% of   12.11MiB in 00:00:13 at 908.91KiB/s \n",
      "[FixupM4a] Correcting container of \"data/youtube//Transformer Neural Networks - EXPLAINED! (Attention is all you need).m4a\"\n",
      "[ExtractAudio] Not converting audio data/youtube//Transformer Neural Networks - EXPLAINED! (Attention is all you need).m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n",
      "Transcribing part 1!\n",
      "Transcribing part 2!\n",
      "Transcribing part 3!\n",
      "Transcribing part 4!\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Recurrent neural nets, they are feed-forward neural networks rolled out over time. As such, they deal with sequence data, where the input has some defined ordering. This gives rise to several types of architectures. The first is vector-to-sequence models. These neural nets take in a fixed-size vector as input, and it outputs a sequence of any length. In image captioning, for example, the input can be a vector representation of an image, and the output, sequence, is a sentence that describes the '"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPGELET\n",
    "#\n",
    "# dit deel uitvoeren duurt snel een aantal minuten; audio transcriben is ook relatief duur $0.006/min of dus $0.36 per uur\n",
    "# geen extreme bedragen, maar voer dit stuk code ook niet te vaak uit\n",
    "\n",
    "# Transformer Neural Networks van CodeEmporium\n",
    "url=\"https://www.youtube.com/watch?v=TQQlZhbC5ps\"\n",
    "\n",
    "save_dir=\"data/youtube/\"\n",
    "\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "docs[0].page_content[0:500]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T12:44:59.853540Z",
     "start_time": "2023-10-26T12:38:33.792892Z"
    }
   },
   "id": "72f0d507e6ad1683"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### URL\n",
    "\n",
    "Je kan ook gewoon alle content van een url inladen, om dan met de data van een website te 'chatten'. De standaard `WebBaseLoader` kan HTML inlezen en beschikbaar maken, dit werkt wel enkel voor sites die niet JavaScript 'heavy' zijn. Om sites die dynamisch opgebouwd worden te kunnen laden heb je een headless browser nodig. Selenium, te gebruiken via `SeleniumURLLoader` is een optie. (hoewel die dingen niet altijd even perfect werken)   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3168eea598d454d"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: dark middle\n",
      "\n",
      "# Enterprise Web Development C#\n",
      "> Chapter 3 - Solving The Problem Domain\n",
      "\n",
      "---\n",
      "### Chapter 3 - Solving The Problem Domain\n",
      "# Table of contents\n",
      "\n",
      "- [The Visual Studio Solution](#vs-solution)\n",
      "- [The sample application](#sample-application)\n",
      "- [Classes](#classes)\n",
      "- [Associations & collections](#associations)\n",
      "- [Inheritance](#inheritance)\n",
      "- [Polymorphism](#polymorphism)\n",
      "- [Abstract class](#abstract-class)\n",
      "- [Interface](#interface)\n",
      "- [Static members](#static-members)\n",
      "- [Domain Driven \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "loader = WebBaseLoader(\"https://raw.githubusercontent.com/HOGENT-Web/csharp/main/chapters/03/slides/presentation.md\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[:500])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T19:23:50.236852Z",
     "start_time": "2023-11-15T19:23:50.053943Z"
    }
   },
   "id": "fc34b27323ab7770"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Document Splitting\n",
    "\n",
    "We willen de tekst in stukken splitsen, maar dat is veel subtieler dan je zou denken. Je wilt de tekst semantisch splitsen, de stukken zullen later een vector encodering krijgen en gebruikt worden om vragen te beantwoorden. Simpel gezegd wil je bijvoorbeeld niet dat een zin half in één stuk zit, en half in een ander.\n",
    "\n",
    "Er zijn een aantal splitters voorzien in [langchain](https://python.langchain.com/docs/modules/data_connection/document_transformers/#text-splitters): `CharacterTextSplitter`, `MarkdownHeaderTextSplitter`, `TokenTextSplitter`, `RecursiveCharacterTextSplitter` enz."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c85ac8f04fb21674"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# de grootte van een stuk\n",
    "chunk_size = 26\n",
    "# overlap tussen stukken\n",
    "chunk_overlap = 4\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:04:01.768854Z",
     "start_time": "2023-11-15T10:04:01.760972Z"
    }
   },
   "id": "89a18302153960b3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['abcdefghijklmnopqrstuvwxyz']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# past net in één stuk, dus de splitter doet sowieso niets\n",
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "c_splitter.split_text(text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:04:07.611116Z",
     "start_time": "2023-11-15T10:04:07.604058Z"
    }
   },
   "id": "dfa420a19b48476b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we voegen spaties toe om de tekst dubbel zo lang te maken\n",
    "text1 = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
    "c_splitter.split_text(text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:08:28.737511Z",
     "start_time": "2023-11-15T10:08:28.734700Z"
    }
   },
   "id": "4442fd348ca5c8f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "De `CharacterTextSplitter` doet ogenschijnlijk niets, dit komt omdat er gesplitst wordt op basis van een specifiek character (standaard een newline), en dus zal een text zonder newlines niet gesplitst worden \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab9e9d65be61ff2e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator=' ' # default, hier expliciet meegegeven\n",
    ")\n",
    "text1 = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
    "c_splitter.split_text(text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:08:48.722776Z",
     "start_time": "2023-11-15T10:08:48.715814Z"
    }
   },
   "id": "497b4796b7ce716e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In de praktijk is deze splitter dus niet zo handig, je wilt liefst zo semantisch mogelijk splitsen (per paragraaf of zin) en pas als die paragrafen / zinnen te lang worden, op basis van een ander character.\n",
    "\n",
    "Daartoe dient de `RecursiveCharacterTextSplitter`, i.p.v. één separator character te gebruiken, geef je een lijst van separators mee, er zal eerst gesplitst worden volgens het eerste character, als de stukken dan nog te lang zijn opnieuw via de tweede, enz.\n",
    "Tot er geen separators meer over zijn of elk stuk klein genoeg geworden is "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5e8627e35b803cd"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # default, dus eerst per paragraaf, dan per zin, dan per woord, dan gewoon op character\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:08:52.331177Z",
     "start_time": "2023-11-15T10:08:52.324073Z"
    }
   },
   "id": "8499b52ced99819c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# als enkel een spatie als separator voorkomt, gedraagt het zich dus identiek aan de `CharacterTextSplitter`\n",
    "text1 = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
    "r_splitter.split_text(text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:08:57.932959Z",
     "start_time": "2023-11-15T10:08:57.925884Z"
    }
   },
   "id": "1fc4c02af4e2fb99"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Under and overfitting\n",
      "A key element is the interplay between the capac-\n",
      "ity of the model, that is its flexibility and ability\n",
      "to fit diverse data, and the amount and quality\n",
      "of the training data. When the capacity is insuf-\n",
      "ficient, the model cannot fit the data, resulting\n",
      "in a high error during training. This is referred\n",
      "to as underfitting.\n",
      "On the contrary, when the amount of data is in-\n",
      "sufficient, as illustrated in Figure 1.2, the model\n",
      "will often learn characteristics specific to the\n",
      "training examples, resulting in excellent perfor-\n",
      "mance during training, at the cost of a worse\n",
      "Figure 1.2: If the amount of training data (black dots)\n",
      "is small compared to the capacity of the model, the\n"
     ]
    }
   ],
   "source": [
    "# we illustreren met een realistisch stuk tekst\n",
    "text2 = pages[15].page_content[:700]\n",
    "print(text2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:15:55.776103Z",
     "start_time": "2023-11-15T10:15:55.768806Z"
    }
   },
   "id": "d15acaed21ba04f7"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "['1.3 Under and overfitting\\nA key element is the interplay between the capac-\\nity of the model, that is its flexibility and ability\\nto fit diverse data,',\n 'and the amount and quality\\nof the training data. When the capacity is insuf-\\nficient, the model cannot fit the data, resulting\\nin a high error during',\n 'training. This is referred\\nto as underfitting.\\nOn the contrary, when the amount of data is in-\\nsufficient, as illustrated in Figure 1.2, the',\n 'model\\nwill often learn characteristics specific to the\\ntraining examples, resulting in excellent perfor-\\nmance during training, at the cost of a',\n 'worse\\nFigure 1.2: If the amount of training data (black dots)\\nis small compared to the capacity of the model, the']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 150\n",
    "chunk_overlap = 0\n",
    "c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator=' ')\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "c_splitter.split_text(text2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:19:44.271097Z",
     "start_time": "2023-11-15T10:19:44.267547Z"
    }
   },
   "id": "3584f1b8943285c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "['1.3 Under and overfitting\\nA key element is the interplay between the capac-\\nity of the model, that is its flexibility and ability',\n 'to fit diverse data, and the amount and quality\\nof the training data. When the capacity is insuf-\\nficient, the model cannot fit the data, resulting',\n 'in a high error during training. This is referred\\nto as underfitting.\\nOn the contrary, when the amount of data is in-',\n 'sufficient, as illustrated in Figure 1.2, the model\\nwill often learn characteristics specific to the',\n 'training examples, resulting in excellent perfor-\\nmance during training, at the cost of a worse',\n 'Figure 1.2: If the amount of training data (black dots)\\nis small compared to the capacity of the model, the']"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soms iets kleinere stukken nemen, maar gesplitst op basis van een newline, geef betere resultaten\n",
    "r_splitter.split_text(text2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:19:22.468322Z",
     "start_time": "2023-11-15T10:19:22.464633Z"
    }
   },
   "id": "a1a24a92f23eb2bf"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# nu toegepast op het volledig document\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "split_pages = r_splitter.split_documents(pages)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:57:53.610304Z",
     "start_time": "2023-11-15T10:57:53.605997Z"
    }
   },
   "id": "1257b6054241ef53"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "print(len(split_pages))\n",
    "print(len(pages))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:58:17.106746Z",
     "start_time": "2023-11-15T10:58:17.099095Z"
    }
   },
   "id": "aa3d0593866d097d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Een andere manier is om te splitsen op basis van tokens. Dit is belangrijk als we met LLM's werken, die een context hebben die beperkt is tot een aantal tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bafc82c6a4e4272"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "t_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:00:36.249763Z",
     "start_time": "2023-11-15T11:00:33.480230Z"
    }
   },
   "id": "d3b15e6fe6b211d7"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['D', 'it', ' is', ' bel', 'ang', 'ri', 'j', 'k']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Dit is belangrijk\"\n",
    "t_splitter.split_text(text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:01:07.116820Z",
     "start_time": "2023-11-15T11:01:07.109146Z"
    }
   },
   "id": "3da0ddb7e0d9f2ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voor markdown files gebruiken we best de `MarkdownHeaderTextSplitter`, zoals de naam suggereert worden markdown files gesplitst op basis van de headers, en de informatie uit die headers komt dan in de metadata terecht."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f689ad468cf2be6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='* **Every idea starts with a project** (app, website...)\\n* Contains all files for **one executable, library or website**\\n* Can contain source code, images, data files...\\n* Contains compiler settings and other configuration  \\n---\\n### The Visual Studio Solution' metadata={'header 1': 'Projects'}\n",
      "{'header 1': 'Projects'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "m_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[(\"#\", \"header 1\"), (\"##\", \"header 2\")])\n",
    "\n",
    "loader = WebBaseLoader(\"https://raw.githubusercontent.com/HOGENT-Web/csharp/main/chapters/03/slides/presentation.md\")\n",
    "\n",
    "markdown_doc = loader.load()\n",
    "\n",
    "# print(markdown_doc[0].page_content[:500])\n",
    "m_split_text = m_splitter.split_text(markdown_doc[0].page_content)\n",
    "print (m_split_text[4])\n",
    "print (m_split_text[4].metadata)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T12:32:09.803649Z",
     "start_time": "2023-11-16T12:32:09.229054Z"
    }
   },
   "id": "94c5b963e3ae0668"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### vectorstores\n",
    "\n",
    "De volgende stap is al deze chunks in een vectorstore op te slaan, zodat we snel en makkelijk 'gelijkaardige' content kunnen terugvinden (die we dan samen met onze vraag naar een LLM doorsturen, maar dat komt later)\n",
    "\n",
    "We dienen eerste vector embeddings te creëren, vector voorstellingen van onze stukken tekst, hiervoor gebruiken we OpenAI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcc24accd63123f7"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903618173120376\n",
      "0.7657950951685688\n",
      "0.7552190470689308\n"
     ]
    }
   ],
   "source": [
    "# klein voorbeeld om te tonen dat gelijkaardige tekst tot gelijkaardige embeddings leidt. \n",
    "\n",
    "embedding1 = embeddings.embed_query(\"De student dronk iets te veel op de cantus\")\n",
    "embedding2 = embeddings.embed_query(\"De student drinkt graag bier op feestjes\")\n",
    "embedding3 = embeddings.embed_query(\"A completely different piece of text about a man who's working very hard on course material\")\n",
    "\n",
    "# print(embedding1)\n",
    "# print(embedding2)\n",
    "# print(embedding3)\n",
    "\n",
    "# het dot product geeft aan in hoeverre twee vectoren in dezelfde richting 'wijzen'\n",
    "# m.a.w. hoe groter het dot product, hoe gelijkaardiger twee vectoren zijn\n",
    "import numpy as np\n",
    "\n",
    "print(np.dot(embedding1, embedding2))\n",
    "print(np.dot(embedding1, embedding3))\n",
    "print(np.dot(embedding2, embedding3))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T19:44:28.705077Z",
     "start_time": "2023-11-15T19:44:27.687901Z"
    }
   },
   "id": "3b17c9f5f87141dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chroma\n",
    "\n",
    "Chroma is een vectorstore die volledig in het geheugen draait, ideaal om snel wat code te runnen (en te demonstreren hier), voor grotere toepassingen bestaan er veel gehoste oplossing ook, langchain heeft bindings voor de meest courant gebruikte."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ad414706c2d9631"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(texts: 'List[str]', chunk_size: 'Optional[int]' = 0) -> 'List[List[float]]'\n"
     ]
    }
   ],
   "source": [
    "from inspect import signature\n",
    "\n",
    "t = signature(embeddings.embed_documents)\n",
    "print (t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T19:58:36.387357Z",
     "start_time": "2023-11-15T19:58:36.378566Z"
    }
   },
   "id": "e4c2fe9a6413462c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Chroma is heel lightweight and werkt\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "chroma_dir = \"data/chroma/\"\n",
    "\n",
    "\n",
    "# chromadb versie 0.4.15 MAXIMUM (in 0.4.16 is het signature van de verwachte embed functie gewijzigd)\n",
    "chromadb = Chroma.from_documents(documents=m_split_text, embedding=embeddings, persist_directory=chroma_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T12:32:19.255123Z",
     "start_time": "2023-11-16T12:32:15.879524Z"
    }
   },
   "id": "143c4a4fe387cf62"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "print(chromadb._collection.count())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T12:33:20.303443Z",
     "start_time": "2023-11-16T12:33:20.295108Z"
    }
   },
   "id": "d7fba208205c326e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "question = \"How does polymorphism work in C#?\"\n",
    "\n",
    "result = chromadb.similarity_search(question, k=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T13:12:38.521434Z",
     "start_time": "2023-11-17T13:12:38.076712Z"
    }
   },
   "id": "6a025626d6654dde"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "> Polymorphism  \n",
      "---\n",
      "### Solving The Problem Domain\n"
     ]
    }
   ],
   "source": [
    "print(len(result))\n",
    "print(result[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T12:35:50.214634Z",
     "start_time": "2023-11-16T12:35:50.206265Z"
    }
   },
   "id": "fbd6ad8ed2cd6585"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "chromadb.persist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T12:36:07.466936Z",
     "start_time": "2023-11-16T12:36:07.458307Z"
    }
   },
   "id": "aa5cbf64bafc9e75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieval\n",
    "\n",
    "Maximum marginal relevance (MMR), als je gewoon de meest gelijkende resultaten zoekt, gebeurt het soms dat je een aantal resultaten terug krijgt die redundant zijn; die eigenlijk allemaal dezelfde inhoud terug geven. MMR kan hier helpen, het algoritme zal naast de relevantie van de resultaten, ook de 'diversiteit' in rekening nemen, en op basis van beide een nieuwe ranking maken. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be670f4a648d67fa"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = 'data/chroma/'\n",
    "\n",
    "chromadb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embeddings\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:35:50.639198Z",
     "start_time": "2023-11-20T15:35:50.455659Z"
    }
   },
   "id": "a04692982d638fe0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='> Polymorphism  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'}), Document(page_content='* **Every class** in C# implicitly **inherits from `System.Object`**\\n* No need to write this\\n* You get these methods for free with this behaviour\\n* `ToString()`: returns the class name\\n* `Equals(Object)`: returns true\\n* if two reference variables reference the same object or\\n* if two value variables have the same value\\n* `GetHashCode()`: used in hash-based collections (e.g. `Dictionary`)  \\n---\\n### Solving The Problem Domain  \\n* **Superclass** contains shared properties and methods\\n* **Subclass inherits all** `public` and `protected` members\\n* `private` members are not accessible/inherited\\n* **Subclass extends or specialises** the superclass\\' behavior\\n* **\"Is a\"** relation between sub- and superclass  \\n---\\n### Inheritance', metadata={'header 1': 'Inheritance'}), Document(page_content='C# has different types of collections, all serving its unique purpose:\\n* **List**: just a simple list of items\\n* **ArrayList**: a simple list to store `object`s, no type is given\\n* **Stack**: LIFO structure\\n* **Queue**: FIFO structure\\n* **Dictionary**: list of key-value pairs in unordered way\\n* **Hashtable**: list of key-value pairs stored by a hash of the key  \\nLearn about collection with this [tutorials](https://www.tutorialsteacher.com/csharp/csharp-collection).  \\n---\\n### Associations & collections', metadata={'header 1': 'Implementations'})]\n"
     ]
    }
   ],
   "source": [
    "# result was het resultaat van een similarity_search\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T13:12:42.969596Z",
     "start_time": "2023-11-17T13:12:42.965027Z"
    }
   },
   "id": "4fdf44cd11ea0618"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='> Polymorphism  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'}),\n Document(page_content='C# has different types of collections, all serving its unique purpose:\\n* **List**: just a simple list of items\\n* **ArrayList**: a simple list to store `object`s, no type is given\\n* **Stack**: LIFO structure\\n* **Queue**: FIFO structure\\n* **Dictionary**: list of key-value pairs in unordered way\\n* **Hashtable**: list of key-value pairs stored by a hash of the key  \\nLearn about collection with this [tutorials](https://www.tutorialsteacher.com/csharp/csharp-collection).  \\n---\\n### Associations & collections', metadata={'header 1': 'Implementations'}),\n Document(page_content='* By default methods cannot be overriden in the subclass\\n* **Keyword `virtual`** is needed in the superclass  \\n```{cs}\\npublic `virtual` void Withdraw(decimal amount)\\n{\\n_transactions.Add(new Transaction(amount, TransactionType.Withdraw));\\nBalance -= amount;\\n}\\n```  \\n* **Keyword `override`** is needed in the subclass  \\n```{cs}\\npublic `override` void Withdraw(decimal amount)\\n{\\nbase.Withdraw(amount);\\nbase.Withdraw(WithdrawCost);\\n}\\n```  \\n---\\n### Inheritance  \\nThe compiler will always choose the right implementation, depending on the runtime type.  \\n```{cs}\\nBankAccount account1 = new BankAccount(\"123-123123-12\");\\nBankAccount account2 = new SavingsAccount(\"123-123123-13\", 0.1M);\\n\\naccount1.Withdraw(100M); // method from BankAccount\\naccount2.Withdraw(100M); // method from SavingsAccount\\n```  \\n---\\n### Inheritance', metadata={'header 1': 'Methods'})]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromadb.max_marginal_relevance_search(question, k=3, fetch_k=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T12:40:28.969269Z",
     "start_time": "2023-11-17T12:40:28.751367Z"
    }
   },
   "id": "1c8630bf9bf8ff46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "SelfQuery, een ander algoritme dat je met langchain kan gebruiken is SelfQuery, het idee is dat je je vraag stelt in 'natuurlijke taal', en dat de LLM zichzelf gebruikt (vandaar de naam) om onderscheid te maken tussen delen van de vraag waarmee de metadata kan gefilterd worden, en de eigenlijk inhoud zelf. \n",
    "\n",
    "Als we kijken welke metadata er in het resultaat van onze similarity_search zit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0226dd4e75234ba"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header 1': 'Solving The Problem Domain'}\n",
      "{'header 1': 'Inheritance'}\n",
      "{'header 1': 'Implementations'}\n"
     ]
    }
   ],
   "source": [
    "for d in result:\n",
    "    print (d.metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T13:12:47.167841Z",
     "start_time": "2023-11-17T13:12:47.163267Z"
    }
   },
   "id": "37595c357758a6ca"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "metadata_info = [AttributeInfo(name=\"header 1\", description=\"The subject of this part of the course\", type=\"string\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:43:49.021684Z",
     "start_time": "2023-11-20T15:43:49.015881Z"
    }
   },
   "id": "60f8452e23dd90d8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "self_retriever = SelfQueryRetriever.from_llm(llm, chromadb, \"C# programming course\", metadata_info, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:40:17.058172Z",
     "start_time": "2023-11-20T15:40:17.033410Z"
    }
   },
   "id": "475c7f249e7a4f81"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='> Polymorphism  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'}), Document(page_content='Now implement the `SavingsAccount` class!  \\n---\\nname: polymorphism\\nclass: dark middle', metadata={'header 1': 'Example'}), Document(page_content='> Domain Driven Design  \\n---\\n### Domain Driven Design', metadata={'header 1': 'Solving The Problem Domain'}), Document(page_content='> Inheritance  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'})]\n"
     ]
    }
   ],
   "source": [
    "docs = self_retriever.get_relevant_documents(\"When is polymorphism useful?\")\n",
    "print(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:40:21.123733Z",
     "start_time": "2023-11-20T15:40:19.443451Z"
    }
   },
   "id": "4c66c5d751cf57a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e4b2f461eae61ce8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='> Polymorphism  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'}), Document(page_content='> Domain Driven Design  \\n---\\n### Domain Driven Design', metadata={'header 1': 'Solving The Problem Domain'}), Document(page_content='> Inheritance  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'}), Document(page_content='> Abstract class  \\n---\\n### Solving The Problem Domain', metadata={'header 1': 'Solving The Problem Domain'})]\n"
     ]
    }
   ],
   "source": [
    "docs = self_retriever.get_relevant_documents(\"When is polymorphism useful, exclude examples\")\n",
    "print(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:44:28.532599Z",
     "start_time": "2023-11-20T15:44:26.526636Z"
    }
   },
   "id": "600232b512f98eef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vragen beantwoorden\n",
    "\n",
    "We hebben gezien hoe we data kunnen inladen, hoe we documenten kunnen splitten en in een vectorstore krijgen, en hoe we dan een relevant document kunnen opvragen voor onze vragen.\n",
    "\n",
    "De volgende stap is nu de LLM deze vraag te laten beantwoorden, met behulp van dit document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be4f0e0a742392fc"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=chromadb.as_retriever())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:50:53.955407Z",
     "start_time": "2023-11-20T15:50:53.944863Z"
    }
   },
   "id": "a421318d7dc4266"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'When is polymorphism useful?', 'result': ' Polymorphism is useful when you need to create objects that share a common interface but have different implementations. This allows for code reuse and flexibility when solving a problem domain.'}\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\" : \"When is polymorphism useful?\"})\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:51:31.144182Z",
     "start_time": "2023-11-20T15:51:29.526270Z"
    }
   },
   "id": "e6b4a6fccc07b786"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Give an example of where polymorphism can be used?', 'result': ' Polymorphism can be used when creating a class hierarchy, where a parent class is inherited by multiple child classes. For example, a `BankAccount` class can be inherited by a `SavingsAccount` class and a `CheckingAccount` class.'}\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": \"Give an example of where polymorphism can be used?\"})\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:52:35.551210Z",
     "start_time": "2023-11-20T15:52:32.487653Z"
    }
   },
   "id": "e1dddc9e2a4d9ce8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks to HOGENT course!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Run chain\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=chromadb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:58:53.564161Z",
     "start_time": "2023-11-20T15:58:53.542880Z"
    }
   },
   "id": "19acf46da1ac7ad1"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Polymorphism can be used to create a base class with shared properties and methods, and then create subclasses that inherit from the base class and can override the shared properties and methods. For example, a SavingsAccount class can inherit from a BankAccount class and override the withdraw method to include a fee. Thanks to HOGENT course!\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": \"Give an example of where polymorphism can be used?\"})\n",
    "print(result[\"result\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T16:00:04.272539Z",
     "start_time": "2023-11-20T16:00:01.571287Z"
    }
   },
   "id": "d56feab5ddee85f0"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='> Polymorphism  \\n---\\n### Solving The Problem Domain' metadata={'header 1': 'Solving The Problem Domain'}\n"
     ]
    }
   ],
   "source": [
    "print(result[\"source_documents\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T16:00:15.964769Z",
     "start_time": "2023-11-20T16:00:15.957039Z"
    }
   },
   "id": "832c45f65e1e47e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### map reduce\n",
    "\n",
    "Als de documenten te uitgebreid zijn, zullen ze al snel groter zijn dan de beschikbare context voor LLM's. Een oplossing is om map reduce toe te passen, simpel gezegd zal je de documenten opsplitsen, de vraag naar elk sturen 'mappen', en dan de verschillende antwoorden 'reducen'.\n",
    "\n",
    "Dit leidt snel tot vrij veel API calls dus we gaan dit hier niet demonstreren. Er zijn voorbeelden en uitleg te vinden op langchain als je dit nodig hebt.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0c1ceb0525d314"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat\n",
    "\n",
    "Om nu echt te kunnen chatten met de data ontbreekt er nog een deel van de puzzel, we moeten de eerder gegeven antwoorden ook kunnen meenemen in een volgende vraag. Zodat we extra verduidelijking kunnen krijgen, zoals we dat tegenwoordig gewend zijn van chatbots.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f55b2ec3adccfe60"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# wat we missen is een chat geheugen\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "qa_conversation = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=chromadb.as_retriever(),\n",
    "    memory=memory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T16:09:05.641770Z",
     "start_time": "2023-11-20T16:09:05.624791Z"
    }
   },
   "id": "6821fe5e7d5f7823"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Give an example of where polymorphism can be used?', 'chat_history': [HumanMessage(content='Give an example of where polymorphism can be used?'), AIMessage(content=' Polymorphism can be used when creating a class hierarchy, where a parent class is inherited by multiple child classes. For example, a `BankAccount` class can be inherited by a `SavingsAccount` class and a `CheckingAccount` class.'), HumanMessage(content='Give an example of where polymorphism can be used?'), AIMessage(content=' Polymorphism can be used to create a class hierarchy by having a parent class and then creating child classes that inherit the properties of the parent class.')], 'answer': ' Polymorphism can be used to create a class hierarchy by having a parent class and then creating child classes that inherit the properties of the parent class.'}\n"
     ]
    }
   ],
   "source": [
    "# opgelet! de key is nu 'question' en niet 'query'\n",
    "result = qa_conversation({\"question\": \"Give an example of where polymorphism can be used?\"})\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T16:10:14.446765Z",
     "start_time": "2023-11-20T16:10:12.138059Z"
    }
   },
   "id": "f02490e0875f5e97"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What would an implementation of a SavingsAccount look like?', 'chat_history': [HumanMessage(content='Give an example of where polymorphism can be used?'), AIMessage(content=' Polymorphism can be used when creating a class hierarchy, where a parent class is inherited by multiple child classes. For example, a `BankAccount` class can be inherited by a `SavingsAccount` class and a `CheckingAccount` class.'), HumanMessage(content='Give an example of where polymorphism can be used?'), AIMessage(content=' Polymorphism can be used to create a class hierarchy by having a parent class and then creating child classes that inherit the properties of the parent class.'), HumanMessage(content='What would an implementation of a SavingsAccount look like?'), AIMessage(content=' Checking the type of the instance is possible with the `is` keyword: \\n```\\nBankAccount s = new SavingsAccount(\"123-123123-13\", 0.1M)\\nif (s is SavingsAccount)\\n{\\n// Do something useful\\n}\\n```')], 'answer': ' Checking the type of the instance is possible with the `is` keyword: \\n```\\nBankAccount s = new SavingsAccount(\"123-123123-13\", 0.1M)\\nif (s is SavingsAccount)\\n{\\n// Do something useful\\n}\\n```'}\n"
     ]
    }
   ],
   "source": [
    "result = qa_conversation({\"question\": \"What would an implementation of a SavingsAccount look like?\"})\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T16:11:16.151638Z",
     "start_time": "2023-11-20T16:11:13.294568Z"
    }
   },
   "id": "435eca598799b5ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

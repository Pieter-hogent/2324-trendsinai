{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain\n",
    "\n",
    "(deels geïnspireerd door een lessenreeks van DeepLearning.ai)\n",
    "\n",
    "Voor we starten gaan we eerst zorgen dat iedereen een werkende setup heeft. Als je vorige keer OpenAI opgezet hebt, en je api key staat nog altijd mooi in de `.env` dan is alles oké.\n",
    "Als je credits op waren, is er een alternatief via [Eden AI](https://www.edenai.co/), Eden AI heeft als business model om via één centrale API (de hunne) allerlei andere AI API's aan te spreken. Maar wat voor ons vooral handig is, is dat je een account kan aanmaken zonder credit card, en dan $10 gratis credits krijgt (en dus kunnen we via hen OpenAI aanspreken)\n",
    "\n",
    "Ga naar [www.edenai.co](https://www.edenai.co/) en maak een account aan.\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/edenai_signup.png\" style=\"width: 700px;\" >\n",
    "</div>\n",
    "\n",
    "\n",
    "Dan kan je bij Account Management je API key vinden\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/edenai_apikey.png\" style=\"width: 700px;\" >\n",
    "</div>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3047d615ba7724e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bewaar nu deze API key ook in je `.env` file (de .env file moet ergens in een parent folder van al je notebooks staan, dus als je de repo gewoon gecloned hebt gewoon in de `2324-trendsinai/` folder zelf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "991dc3aff46d6eb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "OPENAI_API_KEY=sk-YYYYY\n",
    "EDENAI_API_KEY=XXXXXXXX\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9698aa9a6daa2d4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:10.960260Z",
     "start_time": "2023-12-11T10:48:10.377176Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "edenai_api_key = os.getenv('EDENAI_API_KEY')\n",
    "\n",
    "# print (openai.api_key)\n",
    "# print (edenai_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Als je de print commando's uitvoert, zou je de key(s) die je wilt gebruiken moeten zien, als je `None` ziet staan is er iets mis.\n",
    "\n",
    "De key van EdenAI is een Bearer token, daar kennen jullie alles van uit de Webservices cursus. Rechtstreeks de EdenAI API aanspreken doe je met een POST request naar de juiste url.\n",
    "EdenAI heeft véél endpoints, een ChatGPT request zou er als volgt uitzien:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88c88e58a348b026"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"openai\":{\"status\":\"success\",\"generated_text\":\"LangChain offers several advantages:\\n\\n1. Accessibility: LangChain provides a decentralized platform that connects language learners and tutors from around the world. This accessibility allows learners to find tutors who are native speakers of the language they want to learn, ensuring a more authentic learning experience.\\n\\n2. Cost-effective: By eliminating intermediaries and connecting learners directly with tutors, LangChain reduces the cost of language learning. Learners can find tutors at affordable rates, making language learning more accessible to a wider audience.\\n\\n3. Flexibility: LangChain offers flexibility in terms of scheduling and learning pace. Learners can choose tutors based on their availability and can schedule lessons at their convenience. This flexibility allows learners to fit language learning into their busy schedules.\\n\\n4. Personalized learning: LangChain enables personalized learning experiences by connecting learners with tutors who can tailor their teaching methods to the individual's needs and learning style. This personalized approach enhances the effectiveness of language learning.\\n\\n5. Cultural exchange: LangChain promotes cultural exchange by connecting learners with tutors from different countries and backgrounds. This not only helps learners improve their language skills but also provides them with insights into different cultures and perspectives.\\n\\n6. Feedback and progress tracking: LangChain provides a platform for tutors to give feedback and track the progress of learners. This feedback helps learners identify areas for improvement and track their language learning journey.\\n\\n7. Community support: LangChain fosters a supportive community of language learners and tutors. Learners can connect with fellow learners, share resources, and seek advice, creating a collaborative learning environment.\\n\\nOverall, LangChain offers a decentralized, cost-effective, flexible, and personalized approach to language learning, promoting accessibility and cultural exchange while providing a supportive community for learners.\",\"message\":[{\"role\":\"user\",\"message\":\"what are the advantages of langchain?\"},{\"role\":\"assistant\",\"message\":\"LangChain offers several advantages:\\n\\n1. Accessibility: LangChain provides a decentralized platform that connects language learners and tutors from around the world. This accessibility allows learners to find tutors who are native speakers of the language they want to learn, ensuring a more authentic learning experience.\\n\\n2. Cost-effective: By eliminating intermediaries and connecting learners directly with tutors, LangChain reduces the cost of language learning. Learners can find tutors at affordable rates, making language learning more accessible to a wider audience.\\n\\n3. Flexibility: LangChain offers flexibility in terms of scheduling and learning pace. Learners can choose tutors based on their availability and can schedule lessons at their convenience. This flexibility allows learners to fit language learning into their busy schedules.\\n\\n4. Personalized learning: LangChain enables personalized learning experiences by connecting learners with tutors who can tailor their teaching methods to the individual's needs and learning style. This personalized approach enhances the effectiveness of language learning.\\n\\n5. Cultural exchange: LangChain promotes cultural exchange by connecting learners with tutors from different countries and backgrounds. This not only helps learners improve their language skills but also provides them with insights into different cultures and perspectives.\\n\\n6. Feedback and progress tracking: LangChain provides a platform for tutors to give feedback and track the progress of learners. This feedback helps learners identify areas for improvement and track their language learning journey.\\n\\n7. Community support: LangChain fosters a supportive community of language learners and tutors. Learners can connect with fellow learners, share resources, and seek advice, creating a collaborative learning environment.\\n\\nOverall, LangChain offers a decentralized, cost-effective, flexible, and personalized approach to language learning, promoting accessibility and cultural exchange while providing a supportive community for learners.\"}],\"cost\":0.000708}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.edenai.run/v2/text/chat\"\n",
    "\n",
    "payload = {\n",
    "    \"response_as_dict\": True,\n",
    "    \"attributes_as_list\": False,\n",
    "    \"show_original_response\": False,\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"providers\": \"openai\",\n",
    "    \"text\": \"what are the advantages of langchain?\"\n",
    "}\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"authorization\": f\"Bearer {edenai_api_key}\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:19.713674Z",
     "start_time": "2023-12-11T10:48:10.725050Z"
    }
   },
   "id": "9b69b7a377cf9bb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We krijgen een string waar ogenschijnlijk wel een JSON-object in zit met key `openai` (we kunnen dit ook direct naar meerdere LLM's sturen en dan zien we elke response), een `status` (hopelijk success) en dan de `generated_text`, er volgt ook nog een array met de role-user, role-assistant historiek in het geval van openai, en op het einde een `cost`.\n",
    "\n",
    "Toen ik deze vraag stelde, kostte het antwoord mij 0.000708; dus met onze 10 dollar kunnen we een 15.000 van dat soort requests sturen, veel, maar ook niet oneindig.\n",
    "\n",
    "We moeten dit JSON-object wel eerst omzetten naar Python, voor we verder kunnen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "179b32c69405199f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of generated_text\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "data = '{\"openai\":{\"status\":\"success\",\"generated_text\":\"Example of generated_text\" }}'\n",
    "\n",
    "# Parse JSON into an object with attributes corresponding to dict keys.\n",
    "x = json.loads(data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "print(x.openai.generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:19.715603Z",
     "start_time": "2023-12-11T10:48:19.709741Z"
    }
   },
   "id": "d6096caf49f71158"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Als we nu alles samenbrengen kunnen we onze `get_answer` van vorige keer aanpassen om of OpenAI, of EdenAI of GPT4All te gebruiken al naargelang."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "172874dd65896cc0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c13e3d737038ed61"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /Users/pieter/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[32874]: Class GGMLMetalClass is implemented in both /Users/pieter/anaconda3/envs/trendsinai/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x14a714228) and /Users/pieter/anaconda3/envs/trendsinai/lib/python3.11/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x14a5dc228). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falcon_model_load: loading model from '/Users/pieter/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin' - please wait ...\n",
      "falcon_model_load: n_vocab   = 65024\n",
      "falcon_model_load: n_embd    = 4544\n",
      "falcon_model_load: n_head    = 71\n",
      "falcon_model_load: n_head_kv = 1\n",
      "falcon_model_load: n_layer   = 32\n",
      "falcon_model_load: ftype     = 2\n",
      "falcon_model_load: qntvr     = 0\n",
      "falcon_model_load: ggml ctx size = 3872.64 MB\n",
      "falcon_model_load: memory_size =    32.00 MB, n_mem = 65536\n",
      "falcon_model_load: ........................ done\n",
      "falcon_model_load: model size =  3872.59 MB / num tensors = 196\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"ggml-model-gpt4all-falcon-q4_0.bin\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:22.721296Z",
     "start_time": "2023-12-11T10:48:19.714438Z"
    }
   },
   "id": "5177dda8b54bd53a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "class API(Enum):\n",
    "    OPEN_AI = 1\n",
    "    GPT4All = 2\n",
    "    EDEN_AI = 3\n",
    "\n",
    "\n",
    "def get_answer(prompt, which_model=API.OPEN_AI):\n",
    "    if which_model == API.GPT4All:\n",
    "        res = model.generate(prompt)\n",
    "        return res\n",
    "    elif which_model == API.OPEN_AI:\n",
    "        message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        res = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=message\n",
    "        )\n",
    "        return res.choices[0].message[\"content\"]\n",
    "    elif which_model == API.EDEN_AI:\n",
    "        url = \"https://api.edenai.run/v2/text/chat\"\n",
    "\n",
    "        payload = {\n",
    "            \"response_as_dict\": True,\n",
    "            \"attributes_as_list\": False,\n",
    "            \"show_original_response\": False,\n",
    "            \"temperature\": 0,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"providers\": \"openai\",\n",
    "            \"text\": f\"{prompt}\"\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"authorization\": f\"Bearer {edenai_api_key}\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        responseObject = json.loads(response.text, object_hook=lambda d: SimpleNamespace(**d))\n",
    "        return responseObject.openai.generated_text;\n",
    "\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:22.725179Z",
     "start_time": "2023-12-11T10:48:22.723581Z"
    }
   },
   "id": "61e4f54b1eff41f6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT4All\n",
      "?\n",
      "GPT4All is a platform that allows users to interact with artificial intelligence (AI) models like GPT-4. Here are some advantages of using GPT4All:\n",
      "\n",
      "1. Access to AI models: GPT4All provides access to a wide range of AI models, including GPT-4, which is one of the most advanced language models in existence. This gives users the opportunity to interact with cutting-edge AI technology and gain valuable insights into how these models work.\n",
      "2. Easy integration: GPT4All is easy to use and integrates seamlessly with other applications. Users can access the platform from any device, whether it's a laptop, tablet, or smartphone. This makes it convenient for users who want to interact with AI models on-the-go.\n",
      "3. Customization options: GPT4All offers a range of customization options that allow users to tailor their interactions with AI models to meet their specific needs. For example,\n",
      "Open AI\n",
      "OpenAI offers several advantages that make it a prominent player in the field of artificial intelligence. \n",
      "\n",
      "1. Cutting-edge research: OpenAI conducts extensive research in various domains of AI, pushing the boundaries of innovation. Their focus on deep learning, reinforcement learning, and natural language processing contributes to advances in these areas.\n",
      "\n",
      "2. Access to state-of-the-art models: OpenAI has developed and released several groundbreaking AI models, such as GPT-3 and DALL-E, which have revolutionized natural language processing and image generation. These models are accessible to the public, enabling developers and researchers to build upon them.\n",
      "\n",
      "3. Democratizing AI: OpenAI aims to make AI accessible to all and avoids the concentration of power by providing open-source tools and models. This promotes inclusivity, equity, and opportunities for developers, researchers, and businesses to leverage AI technologies.\n",
      "\n",
      "4. Ethical considerations: OpenAI places a strong emphasis on ethical and responsible AI development. They actively work on reducing AI biases, addressing safety concerns, and ensuring that AI benefits all of humanity. OpenAI has committed to using any influence they obtain for the benefit of all.\n",
      "\n",
      "5. Collaboration and partnerships: OpenAI actively collaborates with other organizations, academia, and industry experts. By fostering partnerships, they gather diverse expertise, promote knowledge sharing, and facilitate collective efforts towards solving complex AI challenges.\n",
      "\n",
      "6. AI education and policy impact: OpenAI is committed to educating the public, policymakers, and other stakeholders about AI. They strive to have an impact on policy decisions related to AI by advocating for responsible AI practices, transparency, and appropriate regulations.\n",
      "\n",
      "7. Innovation in robotics: Apart from its focus on AI models and research, OpenAI has also ventured into the field of robotics with the aim of building safe and useful general-purpose robots. This diversification broadens their impact and potential applications of AI technologies.\n",
      "\n",
      "Overall, OpenAI's dedication to cutting-edge research, democratization of AI, ethical principles, collaborations, and focus on societal impact make it advantageous not only for the AI community but also for society as a whole.\n",
      "Eden AI\n",
      "There are several advantages of using EdenAI:\n",
      "\n",
      "1. Ease of use: EdenAI provides a user-friendly interface that allows users to easily access and utilize its various AI models and tools. You don't need to have extensive technical knowledge or coding skills to use the platform.\n",
      "\n",
      "2. Wide range of AI models: EdenAI offers a diverse range of AI models and tools, including image recognition, text generation, language translation, sentiment analysis, and more. This allows users to leverage AI capabilities across various domains and applications.\n",
      "\n",
      "3. High-quality results: The AI models provided by EdenAI are trained on large datasets and have undergone rigorous testing and optimization. This ensures that the models deliver accurate and reliable results.\n",
      "\n",
      "4. Fast and efficient: EdenAI's models are designed to provide quick responses, allowing users to obtain results in real-time. This can be particularly beneficial for time-sensitive tasks or applications that require immediate feedback.\n",
      "\n",
      "5. Cost-effective: EdenAI offers a range of pricing plans, including a free tier, which allows users to access AI capabilities without incurring significant costs. This makes it accessible to individuals, small businesses, and organizations with limited budgets.\n",
      "\n",
      "6. Scalability: EdenAI is built on a scalable infrastructure, which means it can handle a large number of requests simultaneously. This makes it suitable for applications with high traffic or large-scale deployments.\n",
      "\n",
      "7. Continuous improvement: EdenAI is constantly updating and expanding its AI models and tools, incorporating the latest advancements in the field. This ensures that users have access to state-of-the-art AI capabilities and can benefit from ongoing improvements.\n",
      "\n",
      "8. Developer-friendly: EdenAI provides comprehensive documentation, tutorials, and support for developers, making it easy to integrate AI capabilities into their own applications or workflows.\n",
      "\n",
      "Overall, EdenAI offers a powerful and accessible platform for leveraging AI capabilities, enabling users to enhance their productivity, efficiency, and decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "print(\"GPT4All\")\n",
    "print(get_answer(\"What are the advantages of GPT4All\", API.GPT4All))\n",
    "print(\"Open AI\")\n",
    "print(get_answer(\"What are the advantages of OpenAI\", API.OPEN_AI))\n",
    "print(\"Eden AI\")\n",
    "print(get_answer(\"What are the advantages of EdenAI\", API.EDEN_AI))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:57.459878Z",
     "start_time": "2023-12-11T10:48:22.726030Z"
    }
   },
   "id": "803dff20cc541e9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LangChain, waarom?\n",
    "\n",
    "LangChain is een framework dat dient om applicaties die gebruik maken van language models te ontwikkelen. Het laat toe om vrij eenvoudig verschillende componenten aan elkaar te 'chainen' (vandaar de naam), en zo meer gestandaardiseerd allerlei verschillende modellen te gebruiken.\n",
    "\n",
    "Het is zeer snel, zeer groot geworden (al meer dan 1700 contributors op [github](https://github.com/langchain-ai/langchain) voor de python versie, en nog eens 400 voor de js versie)\n",
    "Het leuke is dat je snel veel soorten AI modellen kan gebruiken, of makkelijk uitbreiden met vectorstores en andere extra functionaliteit; en je bij een wissel naar een ander model niet per se alles opnieuw dient te programmeren of aan te passen.\n",
    "\n",
    "Een (voorlopig?) nadeel is dat het zo snel evolueert en groeit dat de documentatie best wel te wensen over laat.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc2dfa7c6a2e8688"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models\n",
    "\n",
    "We gaan eerst een llm model creëeren, je hebt de keuze tussen een EdenAI of OpenAI model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bbb9a5f5b73032"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from langchain.llms import EdenAI, OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.embeddings.edenai import EdenAiEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "class API(Enum):\n",
    "    OPEN_AI = 1\n",
    "    GPT4All = 2\n",
    "    EDEN_AI = 3\n",
    "    \n",
    "\n",
    "def get_llm(which_model=API.OPEN_AI, temperature = 0.0):\n",
    "    if which_model == API.OPEN_AI:\n",
    "        # OpenAI heeft ook een ChatModel, maar dat is niet makkelijk transparent te gebruiken als je ook EdenAI wil gebruiken in dezelfde requests. Als je enkel met OpenAI wenst te werken is dit zeker een goede optie. Je zal dan wel het output formaat moeten aanpassen.\n",
    "        # return ChatOpenAI(temperature=temperature, model=\"gpt-3.5-turbo\")\n",
    "        return OpenAI(temperature=temperature)\n",
    "    elif which_model == API.EDEN_AI:\n",
    "        return EdenAI(edenai_api_key=edenai_api_key,provider=\"openai\", model=\"gpt-3.5-turbo-instruct\", temperature=temperature, max_tokens=250)\n",
    "\n",
    "def get_embedding(which_model=API.OPEN_AI):\n",
    "    if which_model == API.OPEN_AI:\n",
    "        return OpenAIEmbeddings()\n",
    "    elif which_model == API.EDEN_AI:\n",
    "        return EdenAiEmbeddings(edenai_api_key=edenai_api_key,provider=\"openai\")\n",
    "       "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:57.713653Z",
     "start_time": "2023-12-11T10:48:57.459151Z"
    }
   },
   "id": "7f9bdc0f515ebf93"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "preferred_model = API.EDEN_AI\n",
    "\n",
    "# llm = get_llm(API.EDEN_AI, 0.0)\n",
    "# creative_llm = get_llm(API.EDEN_AI, 0.9)\n",
    "llm = get_llm(preferred_model, 0.0)\n",
    "creative_llm = get_llm(preferred_model, 0.9)\n",
    "embeddings = get_embedding(preferred_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:57.717233Z",
     "start_time": "2023-12-11T10:48:57.715014Z"
    }
   },
   "id": "3afea169b09d5047"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompts\n",
    "\n",
    "Om makkelijker prompts te genereren die (deels) variabel zijn heeft LangChain [https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/](PromptTemplates), een PromptTemplate krijgt een string met {variabelen} als `template`, en genereert dan samen met een array van `input_variables` een prompt die kan gebruikt worden voor een llm.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6809c4300e7132"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language', 'text'] template='Translate the text between three backticks to {language}. text: ```{text}```\\n'\n"
     ]
    }
   ],
   "source": [
    "template_string = \"\"\"Translate the text between three backticks to {language}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template_string)\n",
    "\n",
    "print (prompt_template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:57.720136Z",
     "start_time": "2023-12-11T10:48:57.717033Z"
    }
   },
   "id": "2ae02c5037c260e4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text between three backticks to french. text: ```Dit is een tekst in het Nederlands```\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\n```Ceci est un texte en néerlandais```'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_messages = prompt_template.format(\n",
    "    language=\"french\",\n",
    "    text=\"Dit is een tekst in het Nederlands\")\n",
    "print (translate_messages)\n",
    "llm(translate_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:59.096139Z",
     "start_time": "2023-12-11T10:48:57.719260Z"
    }
   },
   "id": "288d4ed488be6b3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output formatting\n",
    "\n",
    "De standaard output is gewoon een stuk tekst. Vaak wil je echter JSON of een ander gestructureerd formaat om dan makkelijker verder te kunnen werken (en 'chainen')\n",
    "\n",
    "Als voorbeeld nemen we een review van Disneyland, genomen uit een dataset van [https://www.kaggle.com/](https://www.kaggle.com/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9f7542d7767ff18"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "review = f\"\"\"If you've ever been to Disneyland anywhere you'll find Disneyland Hong Kong very similar in the layout when you walk into main street! It has a very familiar feel. One of the rides  its a Small World  is absolutely fabulous and worth doing. The day we visited was fairly hot and relatively busy but the queues moved fairly well.\"\"\"\n",
    "\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "location: Was the review about Disneyland Paris, California, Hong Kong or Unknown\n",
    "\n",
    "weather: Was there any indication about the weather conditions, answer with \\\n",
    "'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN' if no information was provided\n",
    "\n",
    "rides: Extract any sentences about the rides,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "location\n",
    "weather\n",
    "rides\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:48:59.099918Z",
     "start_time": "2023-12-11T10:48:59.088267Z"
    }
   },
   "id": "d63045ab7a9aef69"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] template=\"For the following text, extract the following information:\\n\\nlocation: Was the review about Disneyland Paris, California, Hong Kong or Unknown\\n\\nweather: Was there any indication about the weather conditions, answer with 'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN' if no information was provided\\n\\nrides: Extract any sentences about the rides,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\nlocation\\nweather\\nrides\\n\\ntext: {text}\\n\"\n",
      "\n",
      "\n",
      "{\n",
      "    \"location\": \"Hong Kong\",\n",
      "    \"weather\": \"HOT\",\n",
      "    \"rides\": [\"One of the rides  its a Small World  is absolutely fabulous and worth doing.\"]\n",
      "}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mtype\u001B[39m(response)\n\u001B[0;32m---> 11\u001B[0m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(review_template)\n",
    "print(prompt_template)\n",
    "\n",
    "message = prompt_template.format(text=review)\n",
    "response = llm(message)\n",
    "print(response)\n",
    "\n",
    "type(response)\n",
    "response.get('location')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:01.115861Z",
     "start_time": "2023-12-11T10:48:59.100484Z"
    }
   },
   "id": "5b50b924d3a77a88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zoals je kan zien krijgen we een `string` terug van het systeem, het zou natuurlijk veel beter zijn als dit een echt JSON object is. We gebruiken hiervoor [StructuredOutputParser](https://python.langchain.com/docs/modules/model_io/output_parsers/structured)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3803182d9a6ae66a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"location\": string  // Was the review about Disneyland                                     'Paris', 'California', 'Hong Kong' or 'Unknown'\n",
      "\t\"weather\": string  // Was there any indication                                         about the weather conditions, answer with                                         'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN'                                          if no information was provided\n",
      "\t\"rides\": string  // Extract any sentences about                                     the rides, and output them as a comma                                     separated Python list.\n",
      "}\n",
      "```\n",
      "For the following text, extract the following information:\n",
      "\n",
      "location: Was the review about Disneyland Paris, California, Hong Kong or Unknown\n",
      "\n",
      "weather: Was there any indication about the weather conditions, answer with 'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN' if no information was provided\n",
      "\n",
      "rides: Extract any sentences about the rides,and output them as a comma separated Python list.\n",
      "\n",
      "text: If you've ever been to Disneyland anywhere you'll find Disneyland Hong Kong very similar in the layout when you walk into main street! It has a very familiar feel. One of the rides  its a Small World  is absolutely fabulous and worth doing. The day we visited was fairly hot and relatively busy but the queues moved fairly well.\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"location\": string  // Was the review about Disneyland                                     'Paris', 'California', 'Hong Kong' or 'Unknown'\n",
      "\t\"weather\": string  // Was there any indication                                         about the weather conditions, answer with                                         'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN'                                          if no information was provided\n",
      "\t\"rides\": string  // Extract any sentences about                                     the rides, and output them as a comma                                     separated Python list.\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"location\": \"Hong Kong\",\n",
      "\t\"weather\": \"HOT\",\n",
      "\t\"rides\": \"One of the rides its a Small World is absolutely fabulous and worth doing.\"\n",
      "}\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/site-packages/langchain/output_parsers/json.py:163\u001B[0m, in \u001B[0;36mparse_and_check_json_markdown\u001B[0;34m(text, expected_keys)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     json_obj \u001B[38;5;241m=\u001B[39m parse_json_markdown(text)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m json\u001B[38;5;241m.\u001B[39mJSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/site-packages/langchain/output_parsers/json.py:145\u001B[0m, in \u001B[0;36mparse_json_markdown\u001B[0;34m(json_string, parser)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;66;03m# Parse the JSON string into a Python dictionary\u001B[39;00m\n\u001B[0;32m--> 145\u001B[0m parsed \u001B[38;5;241m=\u001B[39m parser(json_str)\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m parsed\n",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_decoder\u001B[38;5;241m.\u001B[39mdecode(s)\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03mcontaining a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_decode(s, idx\u001B[38;5;241m=\u001B[39m_w(s, \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mend())\n\u001B[1;32m    338\u001B[0m end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOutputParserException\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 51\u001B[0m\n\u001B[1;32m     48\u001B[0m response \u001B[38;5;241m=\u001B[39m llm(messages)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n\u001B[0;32m---> 51\u001B[0m output_dict \u001B[38;5;241m=\u001B[39m output_parser\u001B[38;5;241m.\u001B[39mparse(response)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(output_dict)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mtype\u001B[39m(output_dict)\n",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/site-packages/langchain/output_parsers/structured.py:95\u001B[0m, in \u001B[0;36mStructuredOutputParser.parse\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m     94\u001B[0m     expected_keys \u001B[38;5;241m=\u001B[39m [rs\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m rs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_schemas]\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parse_and_check_json_markdown(text, expected_keys)\n",
      "File \u001B[0;32m~/anaconda3/envs/trendsinai/lib/python3.11/site-packages/langchain/output_parsers/json.py:165\u001B[0m, in \u001B[0;36mparse_and_check_json_markdown\u001B[0;34m(text, expected_keys)\u001B[0m\n\u001B[1;32m    163\u001B[0m     json_obj \u001B[38;5;241m=\u001B[39m parse_json_markdown(text)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m json\u001B[38;5;241m.\u001B[39mJSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 165\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OutputParserException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot invalid JSON object. Error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m expected_keys:\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m json_obj:\n",
      "\u001B[0;31mOutputParserException\u001B[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "location_schema = ResponseSchema(name=\"location\",\n",
    "                             description=\"Was the review about Disneyland \\\n",
    "                                    'Paris', 'California', 'Hong Kong' or 'Unknown'\")\n",
    "weather_schema = ResponseSchema(name=\"weather\",\n",
    "                                      description=\"Was there any indication \\\n",
    "                                        about the weather conditions, answer with \\\n",
    "                                        'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN' \\\n",
    "                                         if no information was provided\")\n",
    "ride_schema = ResponseSchema(name=\"rides\",\n",
    "                                    description=\"Extract any sentences about \\\n",
    "                                    the rides, and output them as a comma \\\n",
    "                                    separated Python list.\")\n",
    "\n",
    "response_schemas = [location_schema,\n",
    "                    weather_schema,\n",
    "                    ride_schema]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)\n",
    "\n",
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "location: Was the review about Disneyland Paris, California, Hong Kong or Unknown\n",
    "\n",
    "weather: Was there any indication about the weather conditions, answer with \\\n",
    "'TOO HOT', 'HOT', 'RAIN', 'COLD' or 'UNKNOWN' if no information was provided\n",
    "\n",
    "rides: Extract any sentences about the rides,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format(text=review, format_instructions=format_instructions)\n",
    "print(messages)\n",
    "\n",
    "response = llm(messages)\n",
    "print(response)\n",
    "\n",
    "output_dict = output_parser.parse(response)\n",
    "\n",
    "print(output_dict)\n",
    "type(output_dict)\n",
    "output_dict.get('rides')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:32.842931Z",
     "start_time": "2023-12-11T10:49:30.783948Z"
    }
   },
   "id": "e82c282b17df88bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Indexes\n",
    "\n",
    "### Conversation Memory\n",
    "\n",
    "Met behulp van een [https://python.langchain.com/docs/modules/memory/types/buffer](Conversation Buffer) krijgt je conversatie een 'geheugen', je hoeft niet langer de prompts in hun geheel mee te geven. (standaard start elke prompt van nul, en kan de AI dus geen rekening houden met wat er reeds eerder gezegd is)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16ad605ea1202c88"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.clear()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True # door verbose aan te zetten zien we de volledige chain en prompts verschijnen\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:37.000730Z",
     "start_time": "2023-12-11T10:49:36.771305Z"
    }
   },
   "id": "6621ea0e36a28448"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ik ben een 25-jarige student uit Gent. Ik ben een grote dierenvriend en heb zelf een hond en een kat. Ik ben op zoek naar een bijverdienste en ik zou graag op uw huisdier passen. Ik ben een verantwoordelijke en betrouwbare persoon en ik zal ervoor zorgen dat uw huisdier de beste zorg krijgt. Ik ben beschikbaar om te wandelen, te voeden, te spelen en te verzorgen. Ik ben ook beschikbaar om te overnachten als dat nodig is. Ik kijk ernaar uit om voor uw huisdier te zorgen!\n",
      "\n",
      "Vanaf € 9 per uur /uur\n",
      "\n",
      "Leeftijd: 24\n",
      "\n",
      "Ervaring: 10+ Jaren\n",
      "\n",
      "Ik ben een 24-jarige studente uit Gent. Ik ben een grote dierenvriend en heb zelf een hond en een kat. Ik ben op zoek naar een bijverdienste en ik zou graag op uw huisdier passen. Ik ben een verantwoordelijke en betrouwbare persoon en ik zal ervoor zorgen dat uw huis\n",
      "\n",
      "\n",
      "12\n",
      "\n",
      "\n",
      "Dat kan ik niet weten, ik ben een computerprogramma en heb geen toegang tot persoonlijke informatie.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"Hallo, ik ben Pieter\"))\n",
    "print(llm(\"Hoeveel is 10+2?\"))\n",
    "print(llm(\"Hoe heet ik?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:45.160130Z",
     "start_time": "2023-12-11T10:49:38.412395Z"
    }
   },
   "id": "4891ed6a77d86312"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hallo, ik ben Pieter\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hallo, ik ben Pieter\n",
      "AI:  Hallo Pieter, ik ben een AI ontwikkeld door OpenAI. Mijn naam is GPT-3 en ik ben geprogrammeerd om te communiceren met mensen zoals jij. Wat kan ik voor je doen?\n",
      "Human: Hoeveel is 10+2?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hallo, ik ben Pieter\n",
      "AI:  Hallo Pieter, ik ben een AI ontwikkeld door OpenAI. Mijn naam is GPT-3 en ik ben geprogrammeerd om te communiceren met mensen zoals jij. Wat kan ik voor je doen?\n",
      "Human: Hoeveel is 10+2?\n",
      "AI:   10+2 is 12. Wist je dat GPT-3 in staat is om complexe wiskundige berekeningen uit te voeren? Het is een van mijn vele vaardigheden.\n",
      "Human: Hoe heet ik?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Je hebt me verteld dat je naam Pieter is, dus ik neem aan dat dat je naam is. Als je een andere naam wilt gebruiken, kun je me dat vertellen en zal ik je zo noemen.'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hallo, ik ben Pieter\")\n",
    "conversation.predict(input=\"Hoeveel is 10+2?\")\n",
    "conversation.predict(input=\"Hoe heet ik?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:50.789982Z",
     "start_time": "2023-12-11T10:49:45.157605Z"
    }
   },
   "id": "5ee01a3001da4a9b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hallo, ik ben Pieter\n",
      "AI:  Hallo Pieter, ik ben een AI ontwikkeld door OpenAI. Mijn naam is GPT-3 en ik ben geprogrammeerd om te communiceren met mensen zoals jij. Wat kan ik voor je doen?\n",
      "Human: Hoeveel is 10+2?\n",
      "AI:   10+2 is 12. Wist je dat GPT-3 in staat is om complexe wiskundige berekeningen uit te voeren? Het is een van mijn vele vaardigheden.\n",
      "Human: Hoe heet ik?\n",
      "AI:  Je hebt me verteld dat je naam Pieter is, dus ik neem aan dat dat je naam is. Als je een andere naam wilt gebruiken, kun je me dat vertellen en zal ik je zo noemen.\n"
     ]
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n",
    "print(memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:50.818665Z",
     "start_time": "2023-12-11T10:49:50.790863Z"
    }
   },
   "id": "44b4b92f6c043d78"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bc7dd7873cd70e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Je kan de grootte van je conversation buffer zelf beheren."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fee5425f3c2fb00"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Alles ok, gewoon beetje saaie les AI\n",
      "AI: Hopelijk niet te lang meer dan\n",
      "Human: Hoe heet ik?\n",
      "AI:  Je hebt me verteld dat je Pieter heet, dus dat is hoe ik je noem. Maar als je een andere naam wilt gebruiken, kun je me dat vertellen en ik zal je zo noemen.\n",
      "Human: Hoe heet ik?\n",
      "AI:  Ik heb geen informatie over jouw naam, dus ik kan niet zeggen hoe je heet. Wil je mij jouw naam vertellen zodat ik je in de toekomst kan herkennen?\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\": \"Hallo\"}, {\"output\": \"Hoe gaat het?\"})\n",
    "memory.save_context({\"input\": \"Alles ok, gewoon beetje saaie les AI\"}, {\"output\": \"Hopelijk niet te lang meer dan\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "print(memory.buffer)\n",
    "\n",
    "conversation.predict(input=\"Hallo, ik ben Pieter\")\n",
    "\n",
    "conversation.predict(input=\"Hoe heet ik?\")\n",
    "print(memory.buffer)\n",
    "\n",
    "conversation.predict(input=\"Hoeveel is 10+6?\")\n",
    "\n",
    "conversation.predict(input=\"Hoe heet ik?\")\n",
    "print(memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:49:57.995691Z",
     "start_time": "2023-12-11T10:49:50.796757Z"
    }
   },
   "id": "d14f4c2c8ded73ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In plaats van de buffer te beperken op basis van het aantal vraag-antwoorden, kan je het ook op basis van het aantal tokens doen met behulp van `ConversationTokenBufferMemory`\n",
    "\n",
    "### oefening \n",
    "\n",
    "Gebruik TokenBufferMemory om een deel van een conversatie te beperken, kijk wat er gebeurt als de 'helft' van een zin wegvalt door de limit\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5be15fdecdabe1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Een `ConversationSummaryBufferMemory` gaat niet gewoon alles uit het geheugen gooien als er geen plaats meer is (en alles waarvoor er wel plaats is letterlijk onthouden) maar gaat proberen een samenvatting te maken van wat anders zou verdwijnen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a60a694eeb81c643"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human and AI engage in small talk about their weekend and plans for the day. The AI mentions a busy schedule including a morning class on MLOps, lunch of lasagne, and an interesting lesson on Trends in AI with a focus on LangChain.\n",
      "Human: Wat wordt de interessantse les vandaag?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' De interessantste les vandaag is Trends in AI met een focus op LangChain. Het is een fascinerende les waarin we zullen leren over de nieuwste ontwikkelingen in AI en hoe LangChain een rol speelt in deze ontwikkelingen. Ik ben erg enthousiast om meer te leren over dit onderwerp. Wat zijn jouw plannen voor vandaag?'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# create a long string\n",
    "planning = \"Na een ontbijt 's ochtends moet je tegen 10u naar \\\n",
    "Gent om op tijd te zijn voor de les MLOps \\\n",
    "Na de lasagne als lunch moet je weer klaar zijn \\\n",
    "voor het interessante Machine Learning Operations \\\n",
    "Maar het hoogtepunt van de dag vormt natuurlijk \\\n",
    "de les Trends in AI waar je het vandaag over LangChain \\\n",
    "zal hebben. \\\n",
    "\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hoi\"}, {\"output\": \"Alles goed?\"})\n",
    "memory.save_context({\"input\": \"Ja hoor, weekend weer gedaan\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"Wat staat er op de planning voor vandaag?\"},\n",
    "                    {\"output\": f\"{planning}\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Wat wordt de interessantse les vandaag?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:05.124669Z",
     "start_time": "2023-12-11T10:49:57.995968Z"
    }
   },
   "id": "9644b0aca8e824f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chains\n",
    "\n",
    "Lang*Chain*, er bestaan een heleboel 'Chain' klassen die je toestaan de output van één prompt als input voor de volgende te gebruiken. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1fab74d59589177"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\"AI Innovations: Ontdekkingen in LangChain, Prompt Engineering en ChatGPT\" '"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"Wat is de beste naam voor een vak met als onderwerp {onderwerp}?\"\"\")\n",
    "\n",
    "chain = LLMChain(llm=creative_llm, prompt=prompt)\n",
    "onderwerp = \"LangChain, prompt engineering, chatgpt en meer trendy AI dingen\"\n",
    "\n",
    "chain.run(onderwerp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:06.554894Z",
     "start_time": "2023-12-11T10:50:05.123685Z"
    }
   },
   "id": "367b9199ef6c832d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bij een `SimpleSequentialChain` wordt de output van de ene als input voor de volgende gebruikt, zonder dat er nood is aan een key of iets dergelijks. Het systeem gaat er vanuit dat de output van de ene de (enige) input van de andere is."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89153558ae8f458"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m\n",
      "\n",
      "\"Next-Gen AI: Innovaties in LangChain, Prompt Engineering en ChatGPT\" \u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m is een vak dat zich richt op de nieuwste ontwikkelingen op het gebied van kunstmatige intelligentie, met een focus op toegepaste technologieën zoals LangChain, Prompt Engineering en ChatGPT. Studenten leren over de toepassingen en mogelijkheden van deze innovaties en hoe ze deze kunnen gebruiken om complexe problemen op te lossen en menselijke interactie te verbeteren. Het vak biedt een unieke kans om te werken met cutting-edge tools en technieken en om deel uit te maken van de vooruitgang van AI.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' is een vak dat zich richt op de nieuwste ontwikkelingen op het gebied van kunstmatige intelligentie, met een focus op toegepaste technologieën zoals LangChain, Prompt Engineering en ChatGPT. Studenten leren over de toepassingen en mogelijkheden van deze innovaties en hoe ze deze kunnen gebruiken om complexe problemen op te lossen en menselijke interactie te verbeteren. Het vak biedt een unieke kans om te werken met cutting-edge tools en technieken en om deel uit te maken van de vooruitgang van AI.'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "onderwerp = \"LangChain, prompt engineering, chatgpt en meer trendy AI dingen\"\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = PromptTemplate.from_template(\"\"\"Wat is de beste naam voor een vak met als onderwerp {onderwerp}?\"\"\")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=creative_llm, prompt=first_prompt)\n",
    "\n",
    "# prompt template 2\n",
    "second_prompt = PromptTemplate.from_template(\"\"\"Geef een beschrijving van een 20 tal woorden over het \\\n",
    "    vak:{naam_vak}\"\"\")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=creative_llm, prompt=second_prompt)\n",
    "\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "\n",
    "overall_simple_chain.run(onderwerp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:10.656054Z",
     "start_time": "2023-12-11T10:50:06.552019Z"
    }
   },
   "id": "38968412ffc2191d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Als er iets complexere kettingen dienen gevormd te worden, waar een prompt input dient te krijgen van twee verschillende andere prompts bijvoorbeeld, gebruiken we een `SequentialChain`, hier kan je telkens een key associëren met een output, en zo meer controle krijgen over welke output bij welke input gebruikt wordt. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87301d723e76153b"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'vak_beschrijving': 'Het vak Avantgarde Artificial Intelligence Technologies is gericht op het ontwikkelen en toepassen van technologie op het gebied van kunstmatig intelligentie (AI). Het biedt een grondige kennis over technieken zoals machine learning (ML), deep learning (DL) en natural language processing (NLP) en hun toepassingen. Het omvat ook onderwerpen zoals computer vision, robottechnologie, rekenkracht en architectuur voor AI. Studenten leren concepten te verwerken, te implementeren en te verbeteren in complexe systemen. Ze krijgen bovendien ook de kans om bestaande AI-oplossingen te evalueren om verbeteringen door te voeren.\\n',\n 'vak_beschrijving_engels': '\\n\\nThe course Avantgarde Artificial Intelligence Technologies focuses on the development and application of technology in the field of artificial intelligence (AI). It provides a thorough knowledge of techniques such as machine learning (ML), deep learning (DL), and natural language processing (NLP) and their applications. It also covers topics such as computer vision, robot technology, computing power, and architecture for AI. Students learn how to process, implement, and improve concepts in complex systems. They also have the opportunity to evaluate existing AI solutions and make improvements.',\n 'samenvatting': '\\n\\nCourse on developing and applying AI technology, covering ML, DL, NLP, computer vision, and more.',\n 'extra_uitleg': \" In deze cursus draait alles om het ontwikkelen en toepassen van AI technologie. AI staat voor Artificial Intelligence, wat verwijst naar technologie die in staat is om taken uit te voeren die normaal gesproken menselijke intelligentie vereisen. De cursus richt zich met name op Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP) en computer vision. Machine Learning houdt zich bezig met het ontwikkelen van algoritmes en modellen die in staat zijn om te leren en voorspellingen te doen op basis van data. Deep Learning is een specifieke vorm van Machine Learning waarbij meerdere lagen van neurale netwerken worden gebruikt om complexe taken uit te voeren. Natural Language Processing is gericht op het begrijpen en verwerken van menselijke taal door computers. En computer vision houdt zich bezig met het herkennen en begrijpen van beelden en video's door middel van computer vision-algoritmes. Deze cursus biedt studenten de mogelijkheid om meer te leren over deze AI-technologieën en hoe ze kunnen worden\"}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# dit was een uitvoer van één van de vorige prompts, \"Avantgarde Artificial Intelligence Technologies\" klinkt wel wat fancier dan \"Trends in AI\" eigenlijk\n",
    "vak = \"\"\"Het vak Avantgarde Artificial Intelligence Technologies is gericht op het ontwikkelen en toepassen van technologie op het gebied van kunstmatig \\\n",
    "intelligentie (AI). Het biedt een grondige kennis over technieken zoals machine learning (ML), deep learning (DL) en natural language processing (NLP) en hun \\\n",
    "toepassingen. Het omvat ook onderwerpen zoals computer vision, robottechnologie, rekenkracht en architectuur voor AI. Studenten leren concepten te verwerken, te \\\n",
    "implementeren en te verbeteren in complexe systemen. Ze krijgen bovendien ook de kans om bestaande AI-oplossingen te evalueren om verbeteringen door te voeren.\n",
    "\"\"\"\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = PromptTemplate.from_template(\n",
    "    \"Vertaal de beschrijving van het volgende vak naar het Engels: {vak_beschrijving}\"\n",
    ")\n",
    "chain_one = LLMChain(llm=creative_llm, prompt=first_prompt,\n",
    "                     output_key=\"vak_beschrijving_engels\")\n",
    "\n",
    "second_prompt = PromptTemplate.from_template(\n",
    "    \"Geef een samenvatting van 10 woorden van de volgende beschrijving: {vak_beschrijving_engels}\"\n",
    ")\n",
    "chain_two = LLMChain(llm=creative_llm, prompt=second_prompt,\n",
    "                     output_key=\"samenvatting\")\n",
    "\n",
    "\n",
    "third_prompt = PromptTemplate.from_template(\n",
    "    \"In welke taal is de beschrijving van het volgende vak: {vak_beschrijving}\"\n",
    ")\n",
    "chain_three = LLMChain(llm=creative_llm, prompt=third_prompt, output_key=\"taal\" )\n",
    "\n",
    "fourth_prompt = PromptTemplate.from_template(\n",
    "    \"Geef wat extra uitleg over het vak dat hier samengevat is in de opgegeven taal \"\n",
    "    \"\\n\\nSamenvatting: {samenvatting}\\nTaal: {taal}\"\n",
    ")\n",
    "chain_four = LLMChain(llm=creative_llm, prompt=fourth_prompt,\n",
    "                      output_key=\"extra_uitleg\" )\n",
    "\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"vak_beschrijving\"],\n",
    "    output_variables=[\"vak_beschrijving_engels\", \"samenvatting\",\"extra_uitleg\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "overall_chain(vak)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:19.930662Z",
     "start_time": "2023-12-11T10:50:10.656606Z"
    }
   },
   "id": "af3d39ff8844336e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RetrievalQA: Q&A over documenten\n",
    "\n",
    "We hebben al heel wat klassen van langchain de revue zien passeren en kleinere chains gebouwd. Tijd om eens een wat 'echtere' toepassingen na te bootsen.\n",
    "Nu gaan we een grote(re) hoeveelheid data inladen gebruik makend van een vectorstore; en dan een Q&A systeem over deze data creëeren.\n",
    "\n",
    "Als voorbeeld nemen we een dataset van Steam games, bekijk eerst de data even in een terminal (of iets dergelijks). \n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5737fef699ff1912"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Title: Baldur's Gate 3\\nOriginal Price: $29.99\\nDiscounted Price: $29.99\\nRelease Date: 3 Aug, 2023\\nLink: https://store.steampowered.com/app/1086940/Baldurs_Gate_3/?snr=1_7_7_230_150_1\\nGame Description: Baldur’s Gate 3 is a story-rich, party-based RPG set in the universe of Dungeons & Dragons, where your choices shape a tale of fellowship and betrayal, survival and sacrifice, and the lure of absolute power.\\nRecent Reviews Summary: Overwhelmingly Positive\\nAll Reviews Summary: Very Positive\\nRecent Reviews Number: - 96% of the 128,900 user reviews in the last 30 days are positive.\\nAll Reviews Number: - 94% of the 188,617 user reviews for this game are positive.\\nDeveloper: Larian Studios\\nPublisher: Larian Studios\\nSupported Languages: ['English', 'French', 'German', 'Spanish - Spain', 'Polish', 'Russian', 'Simplified Chinese', 'Turkish', 'Portuguese - Brazil', 'Italian', 'Spanish - Latin America', 'Traditional Chinese', 'Ukrainian']\\nPopular Tags: ['RPG', 'Choices Matter', 'Character Customization', 'Story Rich', 'Adventure', 'Online Co-Op', 'CRPG', 'Multiplayer', 'Fantasy', 'Turn-Based Combat', 'Dungeons & Dragons', 'Co-op Campaign', 'Strategy', 'Singleplayer', 'Romance', 'Class-Based', 'Dark Fantasy', 'Combat', 'Controller', 'Stealth']\\nGame Features: ['Single-player', 'Online Co-op', 'LAN Co-op', 'Steam Achievements', 'Full controller support', 'Steam Cloud']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  Windows 10 64-bit | Processor: |  Intel I5 4690 / AMD FX 8350 | Memory: |  8 GB RAM | Graphics: |  Nvidia GTX 970 / RX 480 (4GB+ of VRAM) | DirectX: |  Version 11 | Storage: |  150 GB available space | Additional Notes: |  SSD required\" metadata={'source': 'data/steamgames_10.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "file = 'data/steamgames_10.csv'\n",
    "\n",
    "loader = CSVLoader(file_path=file, csv_args={\n",
    "    \"delimiter\": \",\",\n",
    "    \"quotechar\": '\"',\n",
    "    \"fieldnames\":  [\"Title\",\"Original Price\",\"Discounted Price\",\"Release Date\",\"Link\",\"Game Description\",\"Recent Reviews Summary\",\"All Reviews Summary\",\"Recent Reviews Number\",\"All Reviews Number\",\"Developer\",\"Publisher\",\"Supported Languages\",\"Popular Tags\",\"Game Features\",\"Minimum Requirements\"]\n",
    "})\n",
    "\n",
    "data = loader.load()\n",
    "print(data[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:19.964535Z",
     "start_time": "2023-12-11T10:50:19.909472Z"
    }
   },
   "id": "d268d8a41be321a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Embeddings` zorgen ervoor dat we een vector representatie van een stuk tekst kunnen genereren., "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f01b4c8125ad64c5"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[-0.0038772349, -0.03442644, 0.0058666533, -0.007105533, 0.005666728]\n"
     ]
    }
   ],
   "source": [
    "embed = embeddings.embed_query(\"We volgen de les Trends in AI\")\n",
    "print(len(embed))\n",
    "print(embed[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:21.345043Z",
     "start_time": "2023-12-11T10:50:19.964440Z"
    }
   },
   "id": "1e1d71104c8bc50d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We kunnen nu similarity searches uitvoeren gebruik makend van vectorstores. Een makkelijk te hanteren versie is de `DocArrayInMemorySearch`. Zoals de naam suggereert gebeurt alles in memory, dus enkel geschikt als de data niet té groot is, maar heeft het grote voordeel dat we geen externe vector store API's moeten aanspreken of configureren."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2333bafe66a84660"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Title: NARAKA: BLADEPOINT\\nOriginal Price: Free\\nDiscounted Price: Free\\nRelease Date: 11 Aug, 2021\\nLink: https://store.steampowered.com/app/1203220/NARAKA_BLADEPOINT/?snr=1_7_7_230_150_1\\nGame Description: Dive into the legends of the Far East in NARAKA: BLADEPOINT; team up with friends in fast-paced melee fights for a Battle Royale experience unlike any other. Find your playstyle with a varied cast of heroes with unique skills. More than 20 million players have already joined the fray, play free now!\\nRecent Reviews Summary: Mostly Positive\\nAll Reviews Summary: \\nRecent Reviews Number: - 75% of the 146,529 user reviews for this game are positive.This product has experienced one or more periods of off-topic review activity.  Based on your preferences, the reviews within these periods have been excluded from this product's Review Score.\\nAll Reviews Number: \\nDeveloper: 24 Entertainment\\nPublisher: NetEase Games Global\\nSupported Languages: ['English', 'Simplified Chinese', 'Traditional Chinese', 'Japanese', 'Korean', 'French', 'German', 'Spanish - Spain', 'Russian', 'Turkish', 'Portuguese - Portugal', 'Vietnamese', 'Thai']\\nPopular Tags: ['Battle Royale', 'Multiplayer', 'Martial Arts', 'PvP', 'Action', 'Female Protagonist', 'Third Person', 'Survival', 'Character Customization', 'Massively Multiplayer', 'Hack and Slash', 'Fighting', 'Swordplay', 'Parkour', 'Adventure', 'Anime', 'Mature', 'Violent', 'Gore', 'Free to Play']\\nGame Features: ['Online PvP', 'In-App Purchases', 'Partial Controller Support']\\nMinimum Requirements: OS: |  Windows 7 64-bit or newer | Processor: |  Intel i5 4th generation or AMD FX 6300 or equivalent | Memory: |  8 GB RAM | Graphics: |  NVIDIA GeForce GTX 750TI or equivalent | DirectX: |  Version 11 | Network: |  Broadband Internet connection | Storage: |  35 GB available space | Additional Notes: |  a) Can run at 720p/60fps; b) We advise you install the game on an SSD for a more streamlined experience. c) Requires “Windows Memory integrity and VBS enablement” to be disabled\" metadata={'source': 'data/steamgames_10.csv', 'row': 10}\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    data,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "query = \"give me a strategy game that released in 2023 and has a high rating\"\n",
    "\n",
    "result = db.similarity_search(query)\n",
    "\n",
    "print(result[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:25.946230Z",
     "start_time": "2023-12-11T10:50:21.336564Z"
    }
   },
   "id": "57ae98639280ca00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zo wordt er wel een gelijkaardig resultaat gevonden, op basis van de vector embedding, maar om wat 'menselijkere' output te krijgen, in de vorm van vraag-antwoord, gebruiken we de `RetrievalQA`\n",
    "\n",
    "Die zal een llm combineren met onze vectordatabank."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac5fc0716e64c38b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      " Baldur's Gate 3, released on August 3, 2023, has a very positive rating on Steam. It is a story-rich, party-based RPG set in the universe of Dungeons & Dragons, with popular tags such as \"Choices Matter\" and \"Strategy.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = db.as_retriever() # we gebruiken de vectorstore als een Retriever, andere interface om basically hetzelfde te bereiken\n",
    "\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = qa_stuff.run(query)\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:29.473226Z",
     "start_time": "2023-12-11T10:50:25.952673Z"
    }
   },
   "id": "deb70206b5b6e05d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Er bestaat ook een makkelijkere manier om hetzelfde te bekomen, een `VectorStoreIndexCreator`, die veel korter juist hetzelfde doet.\n",
    "Alles nog eens opnieuw (dus ook document loaden e.d., om te tonen hoe weinig code nodig is)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c348759a3fa342"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "file = 'data/steamgames_10.csv'\n",
    "# loader = CSVLoader(file_path=file)\n",
    "loader = CSVLoader(file_path=file, csv_args={\n",
    "    \"delimiter\": \",\",\n",
    "    \"quotechar\": '\"',\n",
    "    \"fieldnames\":  [\"Title\",\"Original Price\",\"Discounted Price\",\"Release Date\",\"Link\",\"Game Description\",\"Recent Reviews Summary\",\"All Reviews Summary\",\"Recent Reviews Number\",\"All Reviews Number\",\"Developer\",\"Publisher\",\"Supported Languages\",\"Popular Tags\",\"Game Features\",\"Minimum Requirements\"]\n",
    "})\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:31.278086Z",
     "start_time": "2023-12-11T10:50:29.469278Z"
    }
   },
   "id": "2847a1ef84b87595"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n- [Cyberpunk 2077](https://store.steampowered.com/app/1091500/Cyberpunk_2077/?snr=1_7_7_230_150_1) (Original Price: $29.99, Discounted Price: $14.99, Release Date: 9 Dec, 2020, Reviews Summary: Very Positive)\n- [Baldur's Gate 3](https://store.steampowered.com/app/1086940/Baldurs_Gate_3/?snr=1_7_7_230_150_1) (Original Price: $29.99, Discounted Price: $29.99, Release Date: 3 Aug, 2023, Reviews Summary: Very Positive)\n- [Call of Duty®](https://store.steampowered.com/app/1938090/Call_of_Duty/?snr=1_7_7_230_150_1) (Original Price: Free, Discounted Price: Free, Release Date: 27 Oct, 2022, Reviews Summary: Mixed)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"give me three fairly new games with a high rating that are discounted formatted as a markdown list\"\n",
    "response = index.query(query)\n",
    "\n",
    "display(Markdown(response))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:36.165125Z",
     "start_time": "2023-12-11T10:50:31.283352Z"
    }
   },
   "id": "b9c09267aab40005"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\n- Cyberpunk 2077 ($14.99)\n- Call of Duty® (Free)\n- Rust ($19.99)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = (\"give me three games form the 2020's which cost less than $15 formatted as a markdown list\")\n",
    "response = index.query(query)\n",
    "\n",
    "display(Markdown(response))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:37.384379Z",
     "start_time": "2023-12-11T10:50:36.162154Z"
    }
   },
   "id": "b1fee69cd1b8d865"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evalueren\n",
    "\n",
    "Hoe kunnen we nu zien hoe goed deze chains hun werk doen? We zouden manueel kunnen door onze data gaan en goede voorbeelden vinden, daar vragen op loslaten, en kijken of de antwoorden voldoen.\n",
    "Maar dat schaalt natuurlijk absoluut niet. Dus we gaan een llm chain gebruiken om onze llm chain te evalueren.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "965d06e4438f86b"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pieter/anaconda3/envs/trendsinai/lib/python3.11/site-packages/langchain/chains/llm.py:308: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qa_pairs': {'query': \"What is the release date for Baldur's Gate 3?\", 'answer': \"The release date for Baldur's Gate 3 is 3 Aug, 2023.\"}}\n",
      "page_content=\"Title: Baldur's Gate 3\\nOriginal Price: $29.99\\nDiscounted Price: $29.99\\nRelease Date: 3 Aug, 2023\\nLink: https://store.steampowered.com/app/1086940/Baldurs_Gate_3/?snr=1_7_7_230_150_1\\nGame Description: Baldur’s Gate 3 is a story-rich, party-based RPG set in the universe of Dungeons & Dragons, where your choices shape a tale of fellowship and betrayal, survival and sacrifice, and the lure of absolute power.\\nRecent Reviews Summary: Overwhelmingly Positive\\nAll Reviews Summary: Very Positive\\nRecent Reviews Number: - 96% of the 128,900 user reviews in the last 30 days are positive.\\nAll Reviews Number: - 94% of the 188,617 user reviews for this game are positive.\\nDeveloper: Larian Studios\\nPublisher: Larian Studios\\nSupported Languages: ['English', 'French', 'German', 'Spanish - Spain', 'Polish', 'Russian', 'Simplified Chinese', 'Turkish', 'Portuguese - Brazil', 'Italian', 'Spanish - Latin America', 'Traditional Chinese', 'Ukrainian']\\nPopular Tags: ['RPG', 'Choices Matter', 'Character Customization', 'Story Rich', 'Adventure', 'Online Co-Op', 'CRPG', 'Multiplayer', 'Fantasy', 'Turn-Based Combat', 'Dungeons & Dragons', 'Co-op Campaign', 'Strategy', 'Singleplayer', 'Romance', 'Class-Based', 'Dark Fantasy', 'Combat', 'Controller', 'Stealth']\\nGame Features: ['Single-player', 'Online Co-op', 'LAN Co-op', 'Steam Achievements', 'Full controller support', 'Steam Cloud']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  Windows 10 64-bit | Processor: |  Intel I5 4690 / AMD FX 8350 | Memory: |  8 GB RAM | Graphics: |  Nvidia GTX 970 / RX 480 (4GB+ of VRAM) | DirectX: |  Version 11 | Storage: |  150 GB available space | Additional Notes: |  SSD required\" metadata={'source': 'data/steamgames_10.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "example_gen_chain = QAGenerateChain.from_llm(llm)\n",
    "\n",
    "# genereert een warning, maar de oprichter van langchain zelf zegt dat we ze mogen negeren :)\n",
    "# (zal dus in de toekomst wel nog aangepast worden)\n",
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")\n",
    "\n",
    "print(new_examples[1])\n",
    "print(data[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:45.898738Z",
     "start_time": "2023-12-11T10:50:37.376116Z"
    }
   },
   "id": "44813f2894326f7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dan kunnen we deze vragen uitvoeren en zien of de antwoorden correct gegeven worden, maar manueel schaalt dat natuurlijk weer niet zo goed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2721bce66910665"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' 3 Aug, 2023'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = list(map(lambda i: i[\"qa_pairs\"], new_examples))\n",
    "qa_stuff.run(examples[1][\"query\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:48.651988Z",
     "start_time": "2023-12-11T10:50:45.893801Z"
    }
   },
   "id": "ad80ca3a6606ee26"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"query\": \"What is the release date for Baldur's Gate 3?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"What is the release date for Baldur's Gate 3?\",\n",
      "  \"context\": \"Title: Baldur's Gate 3\\nOriginal Price: $29.99\\nDiscounted Price: $29.99\\nRelease Date: 3 Aug, 2023\\nLink: https://store.steampowered.com/app/1086940/Baldurs_Gate_3/?snr=1_7_7_230_150_1\\nGame Description: Baldur’s Gate 3 is a story-rich, party-based RPG set in the universe of Dungeons & Dragons, where your choices shape a tale of fellowship and betrayal, survival and sacrifice, and the lure of absolute power.\\nRecent Reviews Summary: Overwhelmingly Positive\\nAll Reviews Summary: Very Positive\\nRecent Reviews Number: - 96% of the 128,900 user reviews in the last 30 days are positive.\\nAll Reviews Number: - 94% of the 188,617 user reviews for this game are positive.\\nDeveloper: Larian Studios\\nPublisher: Larian Studios\\nSupported Languages: ['English', 'French', 'German', 'Spanish - Spain', 'Polish', 'Russian', 'Simplified Chinese', 'Turkish', 'Portuguese - Brazil', 'Italian', 'Spanish - Latin America', 'Traditional Chinese', 'Ukrainian']\\nPopular Tags: ['RPG', 'Choices Matter', 'Character Customization', 'Story Rich', 'Adventure', 'Online Co-Op', 'CRPG', 'Multiplayer', 'Fantasy', 'Turn-Based Combat', 'Dungeons & Dragons', 'Co-op Campaign', 'Strategy', 'Singleplayer', 'Romance', 'Class-Based', 'Dark Fantasy', 'Combat', 'Controller', 'Stealth']\\nGame Features: ['Single-player', 'Online Co-op', 'LAN Co-op', 'Steam Achievements', 'Full controller support', 'Steam Cloud']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  Windows 10 64-bit | Processor: |  Intel I5 4690 / AMD FX 8350 | Memory: |  8 GB RAM | Graphics: |  Nvidia GTX 970 / RX 480 (4GB+ of VRAM) | DirectX: |  Version 11 | Storage: |  150 GB available space | Additional Notes: |  SSD required\\n\\nTitle: Title\\nOriginal Price: Original Price\\nDiscounted Price: Discounted Price\\nRelease Date: Release Date\\nLink: Link\\nGame Description: Game Description\\nRecent Reviews Summary: Recent Reviews Summary\\nAll Reviews Summary: All Reviews Summary\\nRecent Reviews Number: Recent Reviews Number\\nAll Reviews Number: All Reviews Number\\nDeveloper: Developer\\nPublisher: Publisher\\nSupported Languages: Supported Languages\\nPopular Tags: Popular Tags\\nGame Features: Game Features\\nMinimum Requirements: Minimum Requirements\\n\\nTitle: PUBG: BATTLEGROUNDS\\nOriginal Price: Free\\nDiscounted Price: Free\\nRelease Date: 21 Dec, 2017\\nLink: https://store.steampowered.com/app/578080/PUBG_BATTLEGROUNDS/?snr=1_7_7_230_150_1\\nGame Description: Play PUBG: BATTLEGROUNDS for free. Land on strategic locations, loot weapons and supplies, and survive to become the last team standing across various, diverse Battlegrounds. Squad up and join the Battlegrounds for the original Battle Royale experience that only PUBG: BATTLEGROUNDS can offer.\\nRecent Reviews Summary: Mixed\\nAll Reviews Summary: Mixed\\nRecent Reviews Number: - 64% of the 13,945 user reviews in the last 30 days are positive.\\nAll Reviews Number: - 57% of the 2,209,987 user reviews for this game are positive.\\nDeveloper: KRAFTON, Inc.\\nPublisher: KRAFTON, Inc.\\nSupported Languages: ['English', 'Korean', 'Simplified Chinese', 'French', 'German', 'Spanish - Spain', 'Arabic', 'Japanese', 'Polish', 'Portuguese - Portugal', 'Russian', 'Turkish', 'Thai', 'Italian', 'Portuguese - Brazil', 'Traditional Chinese', 'Ukrainian']\\nPopular Tags: ['Survival', 'Shooter', 'Battle Royale', 'Multiplayer', 'FPS', 'PvP', 'Third-Person Shooter', 'Action', 'Online Co-Op', 'Tactical', 'Co-op', 'First-Person', 'Strategy', 'Early Access', 'Competitive', 'Third Person', 'Team-Based', 'Difficult', 'Simulation', 'Stealth']\\nGame Features: ['Online PvP', 'Stats', 'Remote Play on Phone', 'Remote Play on Tablet']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  64-bit Windows 10 | Processor: |  Intel Core i5-4430 / AMD FX-6300 | Memory: |  8 GB RAM | Graphics: |  NVIDIA GeForce GTX 960 2GB / AMD Radeon R7 370 2GB | DirectX: |  Version 11 | Network: |  Broadband Internet connection | Storage: |  40 GB available space\\n\\nTitle: Cyberpunk 2077\\nOriginal Price: $29.99\\nDiscounted Price: $14.99\\nRelease Date: 9 Dec, 2020\\nLink: https://store.steampowered.com/app/1091500/Cyberpunk_2077/?snr=1_7_7_230_150_1\\nGame Description: Cyberpunk 2077 is an open-world, action-adventure RPG set in the dark future of Night City — a dangerous megalopolis obsessed with power, glamor, and ceaseless body modification.\\nRecent Reviews Summary: Very Positive\\nAll Reviews Summary: Very Positive\\nRecent Reviews Number: - 90% of the 5,312 user reviews in the last 30 days are positive.This product has experienced one or more periods of off-topic review activity.  Based on your preferences, the reviews within these periods have been excluded from this product's Review Score.\\nAll Reviews Number: - 80% of the 552,224 user reviews for this game are positive.This product has experienced one or more periods of off-topic review activity.  Based on your preferences, the reviews within these periods have been excluded from this product's Review Score.\\nDeveloper: CD PROJEKT RED\\nPublisher: CD PROJEKT RED\\nSupported Languages: ['English', 'French', 'Italian', 'German', 'Spanish - Spain', 'Arabic', 'Czech', 'Hungarian', 'Japanese', 'Korean', 'Polish', 'Portuguese - Brazil', 'Russian', 'Simplified Chinese', 'Spanish - Latin America', 'Thai', 'Traditional Chinese', 'Turkish']\\nPopular Tags: ['Cyberpunk', 'Open World', 'Nudity', 'RPG', 'Singleplayer', 'Sci-fi', 'Futuristic', 'FPS', 'Mature', 'Story Rich', 'First-Person', 'Atmospheric', 'Exploration', 'Action', 'Violent', 'Great Soundtrack', 'Action RPG', 'Adventure', 'Character Customization', 'Immersive Sim']\\nGame Features: ['Single-player', 'Steam Achievements', 'Steam Trading Cards', 'Partial Controller Support', 'Steam Cloud']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  Windows 10 | Processor: |  Intel Core i5-3570K or AMD FX-8310 | Memory: |  8 GB RAM | Graphics: |  NVIDIA GeForce GTX 970 or AMD Radeon RX 470 | DirectX: |  Version 12 | Storage: |  70 GB available space | Additional Notes: |  In this game you will encounter a variety of visual effects that may provide seizures or loss of consciousness in a minority of people. If you or someone you know experiences any of the above symptoms while playing, stop and seek medical attention immediately.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:EdenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nTitle: Baldur's Gate 3\\nOriginal Price: $29.99\\nDiscounted Price: $29.99\\nRelease Date: 3 Aug, 2023\\nLink: https://store.steampowered.com/app/1086940/Baldurs_Gate_3/?snr=1_7_7_230_150_1\\nGame Description: Baldur’s Gate 3 is a story-rich, party-based RPG set in the universe of Dungeons & Dragons, where your choices shape a tale of fellowship and betrayal, survival and sacrifice, and the lure of absolute power.\\nRecent Reviews Summary: Overwhelmingly Positive\\nAll Reviews Summary: Very Positive\\nRecent Reviews Number: - 96% of the 128,900 user reviews in the last 30 days are positive.\\nAll Reviews Number: - 94% of the 188,617 user reviews for this game are positive.\\nDeveloper: Larian Studios\\nPublisher: Larian Studios\\nSupported Languages: ['English', 'French', 'German', 'Spanish - Spain', 'Polish', 'Russian', 'Simplified Chinese', 'Turkish', 'Portuguese - Brazil', 'Italian', 'Spanish - Latin America', 'Traditional Chinese', 'Ukrainian']\\nPopular Tags: ['RPG', 'Choices Matter', 'Character Customization', 'Story Rich', 'Adventure', 'Online Co-Op', 'CRPG', 'Multiplayer', 'Fantasy', 'Turn-Based Combat', 'Dungeons & Dragons', 'Co-op Campaign', 'Strategy', 'Singleplayer', 'Romance', 'Class-Based', 'Dark Fantasy', 'Combat', 'Controller', 'Stealth']\\nGame Features: ['Single-player', 'Online Co-op', 'LAN Co-op', 'Steam Achievements', 'Full controller support', 'Steam Cloud']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  Windows 10 64-bit | Processor: |  Intel I5 4690 / AMD FX 8350 | Memory: |  8 GB RAM | Graphics: |  Nvidia GTX 970 / RX 480 (4GB+ of VRAM) | DirectX: |  Version 11 | Storage: |  150 GB available space | Additional Notes: |  SSD required\\n\\nTitle: Title\\nOriginal Price: Original Price\\nDiscounted Price: Discounted Price\\nRelease Date: Release Date\\nLink: Link\\nGame Description: Game Description\\nRecent Reviews Summary: Recent Reviews Summary\\nAll Reviews Summary: All Reviews Summary\\nRecent Reviews Number: Recent Reviews Number\\nAll Reviews Number: All Reviews Number\\nDeveloper: Developer\\nPublisher: Publisher\\nSupported Languages: Supported Languages\\nPopular Tags: Popular Tags\\nGame Features: Game Features\\nMinimum Requirements: Minimum Requirements\\n\\nTitle: PUBG: BATTLEGROUNDS\\nOriginal Price: Free\\nDiscounted Price: Free\\nRelease Date: 21 Dec, 2017\\nLink: https://store.steampowered.com/app/578080/PUBG_BATTLEGROUNDS/?snr=1_7_7_230_150_1\\nGame Description: Play PUBG: BATTLEGROUNDS for free. Land on strategic locations, loot weapons and supplies, and survive to become the last team standing across various, diverse Battlegrounds. Squad up and join the Battlegrounds for the original Battle Royale experience that only PUBG: BATTLEGROUNDS can offer.\\nRecent Reviews Summary: Mixed\\nAll Reviews Summary: Mixed\\nRecent Reviews Number: - 64% of the 13,945 user reviews in the last 30 days are positive.\\nAll Reviews Number: - 57% of the 2,209,987 user reviews for this game are positive.\\nDeveloper: KRAFTON, Inc.\\nPublisher: KRAFTON, Inc.\\nSupported Languages: ['English', 'Korean', 'Simplified Chinese', 'French', 'German', 'Spanish - Spain', 'Arabic', 'Japanese', 'Polish', 'Portuguese - Portugal', 'Russian', 'Turkish', 'Thai', 'Italian', 'Portuguese - Brazil', 'Traditional Chinese', 'Ukrainian']\\nPopular Tags: ['Survival', 'Shooter', 'Battle Royale', 'Multiplayer', 'FPS', 'PvP', 'Third-Person Shooter', 'Action', 'Online Co-Op', 'Tactical', 'Co-op', 'First-Person', 'Strategy', 'Early Access', 'Competitive', 'Third Person', 'Team-Based', 'Difficult', 'Simulation', 'Stealth']\\nGame Features: ['Online PvP', 'Stats', 'Remote Play on Phone', 'Remote Play on Tablet']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  64-bit Windows 10 | Processor: |  Intel Core i5-4430 / AMD FX-6300 | Memory: |  8 GB RAM | Graphics: |  NVIDIA GeForce GTX 960 2GB / AMD Radeon R7 370 2GB | DirectX: |  Version 11 | Network: |  Broadband Internet connection | Storage: |  40 GB available space\\n\\nTitle: Cyberpunk 2077\\nOriginal Price: $29.99\\nDiscounted Price: $14.99\\nRelease Date: 9 Dec, 2020\\nLink: https://store.steampowered.com/app/1091500/Cyberpunk_2077/?snr=1_7_7_230_150_1\\nGame Description: Cyberpunk 2077 is an open-world, action-adventure RPG set in the dark future of Night City — a dangerous megalopolis obsessed with power, glamor, and ceaseless body modification.\\nRecent Reviews Summary: Very Positive\\nAll Reviews Summary: Very Positive\\nRecent Reviews Number: - 90% of the 5,312 user reviews in the last 30 days are positive.This product has experienced one or more periods of off-topic review activity.  Based on your preferences, the reviews within these periods have been excluded from this product's Review Score.\\nAll Reviews Number: - 80% of the 552,224 user reviews for this game are positive.This product has experienced one or more periods of off-topic review activity.  Based on your preferences, the reviews within these periods have been excluded from this product's Review Score.\\nDeveloper: CD PROJEKT RED\\nPublisher: CD PROJEKT RED\\nSupported Languages: ['English', 'French', 'Italian', 'German', 'Spanish - Spain', 'Arabic', 'Czech', 'Hungarian', 'Japanese', 'Korean', 'Polish', 'Portuguese - Brazil', 'Russian', 'Simplified Chinese', 'Spanish - Latin America', 'Thai', 'Traditional Chinese', 'Turkish']\\nPopular Tags: ['Cyberpunk', 'Open World', 'Nudity', 'RPG', 'Singleplayer', 'Sci-fi', 'Futuristic', 'FPS', 'Mature', 'Story Rich', 'First-Person', 'Atmospheric', 'Exploration', 'Action', 'Violent', 'Great Soundtrack', 'Action RPG', 'Adventure', 'Character Customization', 'Immersive Sim']\\nGame Features: ['Single-player', 'Steam Achievements', 'Steam Trading Cards', 'Partial Controller Support', 'Steam Cloud']\\nMinimum Requirements: Requires a 64-bit processor and operating system | OS: |  Windows 10 | Processor: |  Intel Core i5-3570K or AMD FX-8310 | Memory: |  8 GB RAM | Graphics: |  NVIDIA GeForce GTX 970 or AMD Radeon RX 470 | DirectX: |  Version 12 | Storage: |  70 GB available space | Additional Notes: |  In this game you will encounter a variety of visual effects that may provide seizures or loss of consciousness in a minority of people. If you or someone you know experiences any of the above symptoms while playing, stop and seek medical attention immediately.\\n\\nQuestion: What is the release date for Baldur's Gate 3?\\nHelpful Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:EdenAI] [1.64s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" 3 Aug, 2023\",\n",
      "        \"generation_info\": null\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [1.64s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \" 3 Aug, 2023\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [1.64s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output_text\": \" 3 Aug, 2023\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA] [3.17s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"result\": \" 3 Aug, 2023\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "qa_stuff.run(examples[1][\"query\"])\n",
    "langchain.debug = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:50:51.835075Z",
     "start_time": "2023-12-11T10:50:48.648943Z"
    }
   },
   "id": "7676b60b06208718"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dus we gaan al deze vragen door QAChain sturen "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e2d3f6e75c72fd5"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = qa_stuff.apply(examples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:51:08.196142Z",
     "start_time": "2023-12-11T10:50:51.832122Z"
    }
   },
   "id": "fc17113618118e37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "En dan kunnen we ze allemaal tegelijk laten evalueren met behulp van een QAEvalChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c07c83e7bb45ec6"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is the minimum system requirement for this game?\n",
      "Real Answer: The minimum system requirement for this game can be found under the \"Minimum Requirements\" section in the document.\n",
      "Predicted Answer:  Requires a 64-bit processor and operating system | OS: |  64-bit Windows 7 | Processor: |  AMD FX 4350 or Equivalent, Intel Core i3 6300 or Equivalent | Memory: |  6 GB RAM | Graphics: |  AMD Radeon™ HD 7730, NVIDIA GeForce® GT 640 | DirectX: |  Version 11 | Network: |  Broadband Internet connection | Storage: |  56 GB available space | Additional Notes: |  ~3.8GB for 1 localized language\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What is the release date for Baldur's Gate 3?\n",
      "Real Answer: The release date for Baldur's Gate 3 is 3 Aug, 2023.\n",
      "Predicted Answer:  3 Aug, 2023\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What is the release date for Counter-Strike: Global Offensive?\n",
      "Real Answer: The release date for Counter-Strike: Global Offensive is August 21, 2012.\n",
      "Predicted Answer:  21 Aug, 2012\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the release date for Apex Legends?\n",
      "Real Answer: The release date for Apex Legends is November 4, 2020.\n",
      "Predicted Answer:  4 Nov, 2020\n",
      "Predicted Grade:  CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the release date for Forza Horizon 5?\n",
      "Real Answer: The release date for Forza Horizon 5 is 8 Nov, 2021.\n",
      "Predicted Answer:  8 Nov, 2021\n",
      "Predicted Grade:  CORRECT\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'results': ' CORRECT'}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "graded_outputs = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['results'])\n",
    "    print()\n",
    "\n",
    "graded_outputs[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:51:15.190596Z",
     "start_time": "2023-12-11T10:51:08.191795Z"
    }
   },
   "id": "1ca5c1b9415897ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agents\n",
    "\n",
    "Agents zijn een vrij nieuwe toevoeging aan LangChain, en laten toe om andere soorten externe bronnen toe te voegen. Bijvoorbeeld een rekenmodule, wikipedia of een zoekmachine."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5ffe0b3c8eeef6"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mCould not parse LLM output: \n",
      "\n",
      "Thought: I should use the calculator tool to calculate the percentage.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% * 250\"\n",
      "}\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output:  I should try again with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try using the calculator tool with a different input format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"15% of 250\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3m\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mCould not parse LLM output: \n",
      "\n",
      "Question: Wat is de cosinus van 45º\n",
      "Thought: We can use the calculator tool to find the cosine of 45 degrees.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"cos(45)\"\n",
      "}\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output:  We need to specify the units for the angle in the calculator input.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"cos(45 deg)\"\n",
      "}\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output:  We can also use the Wikipedia tool to find the cosine of 45 degrees.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine of 45 degrees\"\n",
      "}\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output:  We can try specifying the units in the Wikipedia input.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine of 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: We can also try searching for the cosine function on Wikipedia.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: We can try searching for the cosine function on Wikipedia and looking for the value at 45 degrees in radians.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"cosine function at 45 degrees in radians\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3m\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Wat is de cosinus van 45º',\n 'output': 'Agent stopped due to iteration limit or time limit.'}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)\n",
    "\n",
    "agent= initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)\n",
    "\n",
    "agent(\"Wat is 15% van 250\")\n",
    "agent(\"Wat is de cosinus van 45º\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:53:12.946672Z",
     "start_time": "2023-12-11T10:51:15.178868Z"
    }
   },
   "id": "ae38fa177dafb118"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mCould not parse LLM output: \n",
      "\n",
      "Thought: I should use Wikipedia to search for the book that ends with this quote.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"The Party told you to reject the evidence of your eyes and ears. It was their final, most essential command.\"\n",
      "}\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"The Party told you to reject the evidence of your eyes and ears.\"\n",
      "}\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (roman)\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel)\"\n",
      "}\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (boek)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3mCould not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output: Could not parse LLM output:  I should try searching for the quote in a different format.\n",
      "Action:\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"1984 (novel by George Orwell)\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3m\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Welk boek eindigt met de quote 'The Party told you to reject the evidence of your eyes and ears. It was their final, most essential command.' \"\n",
    "result = agent(question) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T10:54:11.712930Z",
     "start_time": "2023-12-11T10:53:12.937538Z"
    }
   },
   "id": "545f27c0de0f4d1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
